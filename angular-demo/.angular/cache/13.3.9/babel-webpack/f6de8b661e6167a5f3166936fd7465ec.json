{"ast":null,"code":"/*!\n * Copyright (c) Microsoft Corporation and contributors. All rights reserved.\n * Licensed under the MIT License.\n */\nimport { assert } from \"@fluidframework/common-utils\";\nimport { ChildLogger } from \"@fluidframework/telemetry-utils\";\nimport { SummaryTreeBuilder } from \"@fluidframework/runtime-utils\";\nimport { NonCollabClient, UnassignedSequenceNumber } from \"./constants\";\nimport { matchProperties } from \"./properties\";\nimport { serializeAsMinSupportedVersion } from \"./snapshotChunks\";\nexport let SnapshotLegacy = /*#__PURE__*/(() => {\n  class SnapshotLegacy {\n    constructor(mergeTree, logger, filename, onCompletion) {\n      var _a, _b;\n\n      this.mergeTree = mergeTree;\n      this.filename = filename;\n      this.onCompletion = onCompletion;\n      this.logger = ChildLogger.create(logger, \"Snapshot\");\n      this.chunkSize = (_b = (_a = mergeTree === null || mergeTree === void 0 ? void 0 : mergeTree.options) === null || _a === void 0 ? void 0 : _a.mergeTreeSnapshotChunkSize) !== null && _b !== void 0 ? _b : SnapshotLegacy.sizeOfFirstChunk;\n    }\n\n    getSeqLengthSegs(allSegments, allLengths, approxSequenceLength, startIndex = 0) {\n      const segs = [];\n      let sequenceLength = 0;\n      let segCount = 0;\n\n      while (sequenceLength < approxSequenceLength && startIndex + segCount < allSegments.length) {\n        const pseg = allSegments[startIndex + segCount];\n        segs.push(pseg);\n        sequenceLength += allLengths[startIndex + segCount];\n        segCount++;\n      }\n\n      return {\n        version: undefined,\n        chunkStartSegmentIndex: startIndex,\n        chunkSegmentCount: segCount,\n        chunkLengthChars: sequenceLength,\n        totalLengthChars: this.header.segmentsTotalLength,\n        totalSegmentCount: allSegments.length,\n        chunkSequenceNumber: this.header.seq,\n        segmentTexts: segs\n      };\n    }\n    /**\n     * Emits the snapshot to an ISummarizeResult. If provided the optional IFluidSerializer will be used when\n     * serializing the summary data rather than JSON.stringify.\n     */\n\n\n    emit(catchUpMsgs, serializer, bind) {\n      var _a, _b;\n\n      const chunk1 = this.getSeqLengthSegs(this.segments, this.segmentLengths, this.chunkSize);\n      let length = chunk1.chunkLengthChars;\n      let segments = chunk1.chunkSegmentCount;\n      const builder = new SummaryTreeBuilder();\n      builder.addBlob(SnapshotLegacy.header, serializeAsMinSupportedVersion(SnapshotLegacy.header, chunk1, this.logger, this.mergeTree.options, serializer, bind));\n\n      if (chunk1.chunkSegmentCount < chunk1.totalSegmentCount) {\n        const chunk2 = this.getSeqLengthSegs(this.segments, this.segmentLengths, this.header.segmentsTotalLength, chunk1.chunkSegmentCount);\n        length += chunk2.chunkLengthChars;\n        segments += chunk2.chunkSegmentCount;\n        builder.addBlob(SnapshotLegacy.body, serializeAsMinSupportedVersion(SnapshotLegacy.body, chunk2, this.logger, this.mergeTree.options, serializer, bind));\n      }\n\n      assert(length === this.header.segmentsTotalLength, 0x05d\n      /* \"emit: mismatch in segmentsTotalLength\" */\n      );\n      assert(segments === chunk1.totalSegmentCount, 0x05e\n      /* \"emit: mismatch in totalSegmentCount\" */\n      );\n\n      if (catchUpMsgs !== undefined && catchUpMsgs.length > 0) {\n        builder.addBlob((_b = (_a = this.mergeTree.options) === null || _a === void 0 ? void 0 : _a.catchUpBlobName) !== null && _b !== void 0 ? _b : SnapshotLegacy.catchupOps, serializer ? serializer.stringify(catchUpMsgs, bind) : JSON.stringify(catchUpMsgs));\n      }\n\n      return builder.getSummaryTree();\n    }\n\n    extractSync() {\n      const collabWindow = this.mergeTree.getCollabWindow();\n      this.seq = collabWindow.minSeq;\n      this.header = {\n        segmentsTotalLength: this.mergeTree.getLength(this.mergeTree.collabWindow.minSeq, NonCollabClient),\n        seq: this.mergeTree.collabWindow.minSeq\n      };\n      const segs = [];\n      let prev;\n\n      const extractSegment = // eslint-disable-next-line max-len\n      (segment, pos, refSeq, clientId, start, end) => {\n        if (segment.seq !== UnassignedSequenceNumber && segment.seq <= this.seq && (segment.removedSeq === undefined || segment.removedSeq === UnassignedSequenceNumber || segment.removedSeq > this.seq)) {\n          if ((prev === null || prev === void 0 ? void 0 : prev.canAppend(segment)) && matchProperties(prev.properties, segment.properties)) {\n            prev = prev.clone();\n            prev.append(segment.clone());\n          } else {\n            if (prev) {\n              segs.push(prev);\n            }\n\n            prev = segment;\n          }\n        }\n\n        return true;\n      };\n\n      this.mergeTree.map({\n        leaf: extractSegment\n      }, this.seq, NonCollabClient, undefined);\n\n      if (prev) {\n        segs.push(prev);\n      }\n\n      this.segments = [];\n      this.segmentLengths = [];\n      let totalLength = 0;\n      segs.map(segment => {\n        totalLength += segment.cachedLength;\n        this.segments.push(segment.toJSONObject());\n        this.segmentLengths.push(segment.cachedLength);\n      }); // We observed this.header.segmentsTotalLength < totalLength to happen in some cases\n      // When this condition happens, we might not write out all segments in getSeqLengthSegs()\n      // when writing out \"body\". Issue #1995 tracks following up on the core of the problem.\n      // In the meantime, this code makes sure we will write out all segments properly\n\n      if (this.header.segmentsTotalLength !== totalLength) {\n        this.logger.sendErrorEvent({\n          eventName: \"SegmentsTotalLengthMismatch\",\n          totalLength,\n          segmentsTotalLength: this.header.segmentsTotalLength\n        });\n        this.header.segmentsTotalLength = totalLength;\n      }\n\n      return this.segments;\n    }\n\n  }\n\n  SnapshotLegacy.header = \"header\";\n  SnapshotLegacy.body = \"body\";\n  SnapshotLegacy.catchupOps = \"catchupOps\"; // Split snapshot into two entries - headers (small) and body (overflow) for faster loading initial content\n  // Please note that this number has no direct relationship to anything other than size of raw text (characters).\n  // As we produce json for the blob (and then send over the wire compressed), this number\n  // is really hard to correlate with any actual metric that matters (like bytes over the wire).\n  // For test with small number of chunks it would be closer to blob size,\n  // for very chunky text, blob size can easily be 4x-8x of that number.\n\n  SnapshotLegacy.sizeOfFirstChunk = 10000; //# sourceMappingURL=snapshotlegacy.js.map\n\n  return SnapshotLegacy;\n})();","map":null,"metadata":{},"sourceType":"module"}