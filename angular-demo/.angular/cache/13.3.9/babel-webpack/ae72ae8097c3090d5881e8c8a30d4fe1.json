{"ast":null,"code":"/*!\n * Copyright (c) Microsoft Corporation and contributors. All rights reserved.\n * Licensed under the MIT License.\n */\n\n/**\n * Manages a queue of work to be batch processed at next javascript turn of execution\n */\nexport class BatchManager {\n  /**\n   * Creates an instance of BatchManager.\n   * @param process - callback to process the work\n   */\n  constructor(process, maxBatchSize = 100) {\n    this.process = process;\n    this.maxBatchSize = maxBatchSize;\n    this.pendingWork = new Map();\n  }\n  /**\n   * Queue up a work item to be processed\n   *\n   * @param id - id of the batch to add the work item to\n   * @param work - the work item to be added\n   */\n\n\n  add(id, work) {\n    if (!this.pendingWork.has(id)) {\n      this.pendingWork.set(id, []);\n    }\n\n    this.pendingWork.get(id).push(work);\n\n    if (this.pendingWork.get(id).length >= this.maxBatchSize) {\n      if (this.pendingTimer !== undefined) {\n        clearTimeout(this.pendingTimer);\n      }\n\n      this.pendingTimer = undefined;\n      this.startWork();\n    } else if (this.pendingTimer === undefined) {\n      this.pendingTimer = setTimeout(() => {\n        this.pendingTimer = undefined;\n        this.startWork();\n      }, 0);\n    }\n  }\n  /**\n   * Process all the pending work item synchronously now\n   */\n\n\n  drain() {\n    this.startWork();\n  }\n\n  startWork() {\n    // Clear the internal flags first to avoid issues in case any of the pending work calls back into\n    // the batch manager. We could also do this with a second setImmediate call but avoiding in order\n    // to process the work quicker.\n    const pendingWork = this.pendingWork;\n    this.pendingWork = new Map(); // TODO log to influx how much pending work there is. We want to limit the size of a batch\n\n    for (const [id, batch] of pendingWork) {\n      this.process(id, batch);\n    }\n  }\n\n} //# sourceMappingURL=batchManager.js.map","map":null,"metadata":{},"sourceType":"module"}