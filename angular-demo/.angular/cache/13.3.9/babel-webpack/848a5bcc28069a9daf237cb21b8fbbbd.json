{"ast":null,"code":"import _asyncToGenerator from \"C:\\\\Users\\\\sdeshpande\\\\Documents\\\\FluidExamples\\\\angular-demo\\\\node_modules\\\\@babel\\\\runtime\\\\helpers\\\\esm\\\\asyncToGenerator.js\";\nimport { AttachState, LoaderHeader } from \"@fluidframework/container-definitions\";\nimport { assert, Trace, TypedEventEmitter, unreachableCase, performance } from \"@fluidframework/common-utils\";\nimport { ChildLogger, raiseConnectedEvent, PerformanceEvent, TaggedLoggerAdapter, loggerToMonitoringContext, TelemetryDataTag } from \"@fluidframework/telemetry-utils\";\nimport { DriverHeader } from \"@fluidframework/driver-definitions\";\nimport { readAndParse, isUnpackedRuntimeMessage } from \"@fluidframework/driver-utils\";\nimport { DataCorruptionError, DataProcessingError, GenericError, UsageError, extractSafePropertiesFromMessage } from \"@fluidframework/container-utils\";\nimport { MessageType, SummaryType } from \"@fluidframework/protocol-definitions\";\nimport { FlushMode, channelsTreeName } from \"@fluidframework/runtime-definitions\";\nimport { addBlobToSummary, addSummarizeResultToSummary, addTreeToSummary, createRootSummarizerNodeWithGC, RequestParser, create404Response, exceptionToResponse, requestFluidObject, responseToException, seqFromTree, calculateStats, TelemetryContext } from \"@fluidframework/runtime-utils\";\nimport { GCDataBuilder, trimLeadingAndTrailingSlashes } from \"@fluidframework/garbage-collector\";\nimport { v4 as uuid } from \"uuid\";\nimport { ContainerFluidHandleContext } from \"./containerHandleContext\";\nimport { FluidDataStoreRegistry } from \"./dataStoreRegistry\";\nimport { Summarizer } from \"./summarizer\";\nimport { SummaryManager } from \"./summaryManager\";\nimport { DeltaScheduler } from \"./deltaScheduler\";\nimport { ReportOpPerfTelemetry, latencyThreshold } from \"./connectionTelemetry\";\nimport { PendingStateManager } from \"./pendingStateManager\";\nimport { pkgVersion } from \"./packageVersion\";\nimport { BlobManager } from \"./blobManager\";\nimport { DataStores, getSummaryForDatastores } from \"./dataStores\";\nimport { aliasBlobName, blobsTreeName, chunksBlobName, electedSummarizerBlobName, extractSummaryMetadataMessage, metadataBlobName, wrapSummaryInChannelsTree } from \"./summaryFormat\";\nimport { SummaryCollection } from \"./summaryCollection\";\nimport { OrderedClientCollection, OrderedClientElection } from \"./orderedClientElection\";\nimport { SummarizerClientElection, summarizerClientType } from \"./summarizerClientElection\";\nimport { formExponentialFn, Throttler } from \"./throttler\";\nimport { RunWhileConnectedCoordinator } from \"./runWhileConnectedCoordinator\";\nimport { GarbageCollector, GCNodeType, gcTreeKey } from \"./garbageCollection\";\nimport { channelToDataStore, isDataStoreAliasMessage } from \"./dataStore\";\nimport { BindBatchTracker } from \"./batchTracker\";\nimport { SerializedSnapshotStorage } from \"./serializedSnapshotStorage\";\nimport { OpTracker } from \"./opTelemetry\";\nexport var ContainerMessageType = /*#__PURE__*/(() => {\n  (function (ContainerMessageType) {\n    // An op to be delivered to store\n    ContainerMessageType[\"FluidDataStoreOp\"] = \"component\"; // Creates a new store\n\n    ContainerMessageType[\"Attach\"] = \"attach\"; // Chunked operation.\n\n    ContainerMessageType[\"ChunkedOp\"] = \"chunkedOp\"; // Signifies that a blob has been attached and should not be garbage collected by storage\n\n    ContainerMessageType[\"BlobAttach\"] = \"blobAttach\"; // Ties our new clientId to our old one on reconnect\n\n    ContainerMessageType[\"Rejoin\"] = \"rejoin\"; // Sets the alias of a root data store\n\n    ContainerMessageType[\"Alias\"] = \"alias\";\n  })(ContainerMessageType || (ContainerMessageType = {}));\n\n  return ContainerMessageType;\n})();\nexport const DefaultSummaryConfiguration = {\n  state: \"enabled\",\n  idleTime: 5000 * 3,\n  maxTime: 5000 * 12,\n  maxOps: 100,\n  minOpsForLastSummaryAttempt: 10,\n  maxAckWaitTime: 6 * 10 * 1000,\n  maxOpsSinceLastSummary: 7000,\n  initialSummarizerDelayMs: 5000,\n  summarizerClientElection: false\n};\n/**\n * Accepted header keys for requests coming to the runtime.\n */\n\nexport var RuntimeHeaders = /*#__PURE__*/(() => {\n  (function (RuntimeHeaders) {\n    /** True to wait for a data store to be created and loaded before returning it. */\n    RuntimeHeaders[\"wait\"] = \"wait\";\n    /**\n     * True if the request is from an external app. Used for GC to handle scenarios where a data store\n     * is deleted and requested via an external app.\n     */\n\n    RuntimeHeaders[\"externalRequest\"] = \"externalRequest\";\n    /** True if the request is coming from an IFluidHandle. */\n\n    RuntimeHeaders[\"viaHandle\"] = \"viaHandle\";\n  })(RuntimeHeaders || (RuntimeHeaders = {}));\n\n  return RuntimeHeaders;\n})();\nconst useDataStoreAliasingKey = \"Fluid.ContainerRuntime.UseDataStoreAliasing\";\nconst maxConsecutiveReconnectsKey = \"Fluid.ContainerRuntime.MaxConsecutiveReconnects\"; // Feature gate for the max op size. If the value is negative, chunking is enabled\n// and all ops over 16k would be chunked. If the value is positive, all ops with\n// a size strictly larger will be rejected and the container closed with an error.\n\nconst maxOpSizeInBytesKey = \"Fluid.ContainerRuntime.MaxOpSizeInBytes\"; // By default, we should reject any op larger than 768KB,\n// in order to account for some extra overhead from serialization\n// to not reach the 1MB limits in socket.io and Kafka.\n\nconst defaultMaxOpSizeInBytes = 768000; // By default, the size of the contents for the incoming ops is tracked.\n// However, in certain situations, this may incur a performance hit.\n// The feature-gate below can be used to disable this feature.\n\nconst disableOpTrackingKey = \"Fluid.ContainerRuntime.DisableOpTracking\";\nconst defaultFlushMode = FlushMode.TurnBased;\nexport var RuntimeMessage = /*#__PURE__*/(() => {\n  (function (RuntimeMessage) {\n    RuntimeMessage[\"FluidDataStoreOp\"] = \"component\";\n    RuntimeMessage[\"Attach\"] = \"attach\";\n    RuntimeMessage[\"ChunkedOp\"] = \"chunkedOp\";\n    RuntimeMessage[\"BlobAttach\"] = \"blobAttach\";\n    RuntimeMessage[\"Rejoin\"] = \"rejoin\";\n    RuntimeMessage[\"Alias\"] = \"alias\";\n    RuntimeMessage[\"Operation\"] = \"op\";\n  })(RuntimeMessage || (RuntimeMessage = {}));\n\n  return RuntimeMessage;\n})();\nexport function isRuntimeMessage(message) {\n  if (Object.values(RuntimeMessage).includes(message.type)) {\n    return true;\n  }\n\n  return false;\n}\nexport function unpackRuntimeMessage(message) {\n  if (message.type === MessageType.Operation) {\n    // legacy op format?\n    if (message.contents.address !== undefined && message.contents.type === undefined) {\n      message.type = ContainerMessageType.FluidDataStoreOp;\n    } else {\n      // new format\n      const innerContents = message.contents;\n      assert(innerContents.type !== undefined, 0x121\n      /* \"Undefined inner contents type!\" */\n      );\n      message.type = innerContents.type;\n      message.contents = innerContents.contents;\n    }\n\n    assert(isUnpackedRuntimeMessage(message), 0x122\n    /* \"Message to unpack is not proper runtime message\" */\n    );\n  } else {// Legacy format, but it's already \"unpacked\",\n    // i.e. message.type is actually ContainerMessageType.\n    // Nothing to do in such case.\n  }\n\n  return message;\n}\n/**\n * This class controls pausing and resuming of inbound queue to ensure that we never\n * start processing ops in a batch IF we do not have all ops in the batch.\n */\n\nclass ScheduleManagerCore {\n  constructor(deltaManager, logger) {\n    this.deltaManager = deltaManager;\n    this.logger = logger;\n    this.localPaused = false;\n    this.timePaused = 0;\n    this.batchCount = 0; // Listen for delta manager sends and add batch metadata to messages\n\n    this.deltaManager.on(\"prepareSend\", messages => {\n      if (messages.length === 0) {\n        return;\n      } // First message will have the batch flag set to true if doing a batched send\n\n\n      const firstMessageMetadata = messages[0].metadata;\n\n      if (!(firstMessageMetadata === null || firstMessageMetadata === void 0 ? void 0 : firstMessageMetadata.batch)) {\n        return;\n      } // If the batch contains only a single op, clear the batch flag.\n\n\n      if (messages.length === 1) {\n        delete firstMessageMetadata.batch;\n        return;\n      } // Set the batch flag to false on the last message to indicate the end of the send batch\n\n\n      const lastMessage = messages[messages.length - 1];\n      lastMessage.metadata = Object.assign(Object.assign({}, lastMessage.metadata), {\n        batch: false\n      });\n    }); // Listen for updates and peek at the inbound\n\n    this.deltaManager.inbound.on(\"push\", message => {\n      this.trackPending(message);\n    }); // Start with baseline - empty inbound queue.\n\n    assert(!this.localPaused, 0x293\n    /* \"initial state\" */\n    );\n    const allPending = this.deltaManager.inbound.toArray();\n\n    for (const pending of allPending) {\n      this.trackPending(pending);\n    } // We are intentionally directly listening to the \"op\" to inspect system ops as well.\n    // If we do not observe system ops, we are likely to hit 0x296 assert when system ops\n    // precedes start of incomplete batch.\n\n\n    this.deltaManager.on(\"op\", message => this.afterOpProcessing(message.sequenceNumber));\n  }\n  /**\n   * The only public function in this class - called when we processed an op,\n   * to make decision if op processing should be paused or not afer that.\n   */\n\n\n  afterOpProcessing(sequenceNumber) {\n    assert(!this.localPaused, 0x294\n    /* \"can't have op processing paused if we are processing an op\" */\n    ); // If the inbound queue is ever empty, nothing to do!\n\n    if (this.deltaManager.inbound.length === 0) {\n      assert(this.pauseSequenceNumber === undefined, 0x295\n      /* \"there should be no pending batch if we have no ops\" */\n      );\n      return;\n    } // The queue is\n    // 1. paused only when the next message to be processed is the beginning of a batch. Done in two places:\n    //    - here (processing ops until reaching start of incomplete batch)\n    //    - in trackPending(), when queue was empty and start of batch showed up.\n    // 2. resumed when batch end comes in (in trackPending())\n    // do we have incomplete batch to worry about?\n\n\n    if (this.pauseSequenceNumber !== undefined) {\n      assert(sequenceNumber < this.pauseSequenceNumber, 0x296\n      /* \"we should never start processing incomplete batch!\" */\n      ); // If the next op is the start of incomplete batch, then we can't process it until it's fully in - pause!\n\n      if (sequenceNumber + 1 === this.pauseSequenceNumber) {\n        this.pauseQueue();\n      }\n    }\n  }\n\n  pauseQueue() {\n    assert(!this.localPaused, 0x297\n    /* \"always called from resumed state\" */\n    );\n    this.localPaused = true;\n    this.timePaused = performance.now(); // eslint-disable-next-line @typescript-eslint/no-floating-promises\n\n    this.deltaManager.inbound.pause();\n  }\n\n  resumeQueue(startBatch, messageEndBatch) {\n    const endBatch = messageEndBatch.sequenceNumber;\n    const duration = this.localPaused ? performance.now() - this.timePaused : undefined;\n    this.batchCount++;\n\n    if (this.batchCount % 1000 === 1) {\n      this.logger.sendTelemetryEvent({\n        eventName: \"BatchStats\",\n        sequenceNumber: endBatch,\n        length: endBatch - startBatch + 1,\n        msnDistance: endBatch - messageEndBatch.minimumSequenceNumber,\n        duration,\n        batchCount: this.batchCount,\n        interrupted: this.localPaused\n      });\n    } // Return early if no change in value\n\n\n    if (!this.localPaused) {\n      return;\n    }\n\n    this.localPaused = false; // Random round number - we want to know when batch waiting paused op processing.\n\n    if (duration !== undefined && duration > latencyThreshold) {\n      this.logger.sendErrorEvent({\n        eventName: \"MaxBatchWaitTimeExceeded\",\n        duration,\n        sequenceNumber: endBatch,\n        length: endBatch - startBatch\n      });\n    }\n\n    this.deltaManager.inbound.resume();\n  }\n  /**\n   * Called for each incoming op (i.e. inbound \"push\" notification)\n   */\n\n\n  trackPending(message) {\n    assert(this.deltaManager.inbound.length !== 0, 0x298\n    /* \"we have something in the queue that generates this event\" */\n    );\n    assert(this.currentBatchClientId === undefined === (this.pauseSequenceNumber === undefined), 0x299\n    /* \"non-synchronized state\" */\n    );\n    const metadata = message.metadata;\n    const batchMetadata = metadata === null || metadata === void 0 ? void 0 : metadata.batch; // Protocol messages are never part of a runtime batch of messages\n\n    if (!isUnpackedRuntimeMessage(message)) {\n      // Protocol messages should never show up in the middle of the batch!\n      assert(this.currentBatchClientId === undefined, 0x29a\n      /* \"System message in the middle of batch!\" */\n      );\n      assert(batchMetadata === undefined, 0x29b\n      /* \"system op in a batch?\" */\n      );\n      assert(!this.localPaused, 0x29c\n      /* \"we should be processing ops when there is no active batch\" */\n      );\n      return;\n    }\n\n    if (this.currentBatchClientId === undefined && batchMetadata === undefined) {\n      assert(!this.localPaused, 0x29d\n      /* \"we should be processing ops when there is no active batch\" */\n      );\n      return;\n    } // If the client ID changes then we can move the pause point. If it stayed the same then we need to check.\n    // If batchMetadata is not undefined then if it's true we've begun a new batch - if false we've ended\n    // the previous one\n\n\n    if (this.currentBatchClientId !== undefined || batchMetadata === false) {\n      if (this.currentBatchClientId !== message.clientId) {\n        // \"Batch not closed, yet message from another client!\"\n        throw new DataCorruptionError(\"OpBatchIncomplete\", Object.assign({\n          runtimeVersion: pkgVersion,\n          batchClientId: this.currentBatchClientId\n        }, extractSafePropertiesFromMessage(message)));\n      }\n    } // The queue is\n    // 1. paused only when the next message to be processed is the beginning of a batch. Done in two places:\n    //    - in afterOpProcessing() - processing ops until reaching start of incomplete batch\n    //    - here (batchMetadata == false below), when queue was empty and start of batch showed up.\n    // 2. resumed when batch end comes in (batchMetadata === true case below)\n\n\n    if (batchMetadata) {\n      assert(this.currentBatchClientId === undefined, 0x29e\n      /* \"there can't be active batch\" */\n      );\n      assert(!this.localPaused, 0x29f\n      /* \"we should be processing ops when there is no active batch\" */\n      );\n      this.pauseSequenceNumber = message.sequenceNumber;\n      this.currentBatchClientId = message.clientId; // Start of the batch\n      // Only pause processing if queue has no other ops!\n      // If there are any other ops in the queue, processing will be stopped when they are processed!\n\n      if (this.deltaManager.inbound.length === 1) {\n        this.pauseQueue();\n      }\n    } else if (batchMetadata === false) {\n      assert(this.pauseSequenceNumber !== undefined, 0x2a0\n      /* \"batch presence was validated above\" */\n      ); // Batch is complete, we can process it!\n\n      this.resumeQueue(this.pauseSequenceNumber, message);\n      this.pauseSequenceNumber = undefined;\n      this.currentBatchClientId = undefined;\n    } else {\n      // Continuation of current batch. Do nothing\n      assert(this.currentBatchClientId !== undefined, 0x2a1\n      /* \"logic error\" */\n      );\n    }\n  }\n\n}\n/**\n * This class has the following responsibilities:\n * 1. It tracks batches as we process ops and raises \"batchBegin\" and \"batchEnd\" events.\n *    As part of it, it validates batch correctness (i.e. no system ops in the middle of batch)\n * 2. It creates instance of ScheduleManagerCore that ensures we never start processing ops from batch\n *    unless all ops of the batch are in.\n */\n\n\nexport class ScheduleManager {\n  constructor(deltaManager, emitter, logger) {\n    this.deltaManager = deltaManager;\n    this.emitter = emitter;\n    this.logger = logger;\n    this.hitError = false;\n    this.deltaScheduler = new DeltaScheduler(this.deltaManager, ChildLogger.create(this.logger, \"DeltaScheduler\"));\n    void new ScheduleManagerCore(deltaManager, logger);\n  }\n\n  beforeOpProcessing(message) {\n    var _a;\n\n    if (this.batchClientId !== message.clientId) {\n      assert(this.batchClientId === undefined, 0x2a2\n      /* \"Batch is interrupted by other client op. Should be caught by trackPending()\" */\n      ); // This could be the beginning of a new batch or an individual message.\n\n      this.emitter.emit(\"batchBegin\", message);\n      this.deltaScheduler.batchBegin(message);\n      const batch = (_a = message === null || message === void 0 ? void 0 : message.metadata) === null || _a === void 0 ? void 0 : _a.batch;\n\n      if (batch) {\n        this.batchClientId = message.clientId;\n      } else {\n        this.batchClientId = undefined;\n      }\n    }\n  }\n\n  afterOpProcessing(error, message) {\n    var _a; // If this is no longer true, we need to revisit what we do where we set this.hitError.\n\n\n    assert(!this.hitError, 0x2a3\n    /* \"container should be closed on any error\" */\n    );\n\n    if (error) {\n      // We assume here that loader will close container and stop processing all future ops.\n      // This is implicit dependency. If this flow changes, this code might no longer be correct.\n      this.hitError = true;\n      this.batchClientId = undefined;\n      this.emitter.emit(\"batchEnd\", error, message);\n      this.deltaScheduler.batchEnd(message);\n      return;\n    }\n\n    const batch = (_a = message === null || message === void 0 ? void 0 : message.metadata) === null || _a === void 0 ? void 0 : _a.batch; // If no batchClientId has been set then we're in an individual batch. Else, if we get\n    // batch end metadata, this is end of the current batch.\n\n    if (this.batchClientId === undefined || batch === false) {\n      this.batchClientId = undefined;\n      this.emitter.emit(\"batchEnd\", undefined, message);\n      this.deltaScheduler.batchEnd(message);\n      return;\n    }\n  }\n\n}\n/**\n * Legacy ID for the built-in AgentScheduler.  To minimize disruption while removing it, retaining this as a\n * special-case for document dirty state.  Ultimately we should have no special-cases from the\n * ContainerRuntime's perspective.\n */\n\nexport const agentSchedulerId = \"_scheduler\"; // safely check navigator and get the hardware spec value\n\nexport function getDeviceSpec() {\n  try {\n    if (typeof navigator === \"object\" && navigator !== null) {\n      return {\n        deviceMemory: navigator.deviceMemory,\n        hardwareConcurrency: navigator.hardwareConcurrency\n      };\n    }\n  } catch (_a) {}\n\n  return {};\n}\n/**\n * Represents the runtime of the container. Contains helper functions/state of the container.\n * It will define the store level mappings.\n */\n\nexport class ContainerRuntime extends TypedEventEmitter {\n  constructor(context, registry, metadata, electedSummarizerData, chunks, dataStoreAliasMap, runtimeOptions, containerScope, logger, existing, blobManagerSnapshot, _storage, requestHandler, summaryConfiguration) {\n    var _this;\n\n    var _a, _b, _c, _d, _e, _f, _g, _h, _j;\n\n    if (summaryConfiguration === void 0) {\n      summaryConfiguration = Object.assign(Object.assign({}, DefaultSummaryConfiguration), (_a = runtimeOptions.summaryOptions) === null || _a === void 0 ? void 0 : _a.summaryConfigOverrides);\n    }\n\n    super();\n    _this = this;\n    this.context = context;\n    this.registry = registry;\n    this.runtimeOptions = runtimeOptions;\n    this.containerScope = containerScope;\n    this.logger = logger;\n    this._storage = _storage;\n    this.requestHandler = requestHandler;\n    this.summaryConfiguration = summaryConfiguration;\n    this.defaultMaxConsecutiveReconnects = 15;\n    this._orderSequentiallyCalls = 0;\n    this.needsFlush = false;\n    this.flushTrigger = false;\n    this.savedOps = [];\n    this.consecutiveReconnects = 0;\n    this._disposed = false;\n    this.emitDirtyDocumentEvent = true;\n    this.defaultTelemetrySignalSampleCount = 100;\n    this._perfSignalData = {\n      signalsLost: 0,\n      signalSequenceNumber: 0,\n      signalTimestamp: 0,\n      trackingSignalSequenceNumber: undefined\n    };\n\n    this.summarizeOnDemand = (...args) => {\n      if (this.clientDetails.type === summarizerClientType) {\n        return this.summarizer.summarizeOnDemand(...args);\n      } else if (this.summaryManager !== undefined) {\n        return this.summaryManager.summarizeOnDemand(...args);\n      } else {\n        // If we're not the summarizer, and we don't have a summaryManager, we expect that\n        // disableSummaries is turned on. We are throwing instead of returning a failure here,\n        // because it is a misuse of the API rather than an expected failure.\n        throw new UsageError(`Can't summarize, disableSummaries: ${this.summariesDisabled}`);\n      }\n    };\n\n    this.enqueueSummarize = (...args) => {\n      if (this.clientDetails.type === summarizerClientType) {\n        return this.summarizer.enqueueSummarize(...args);\n      } else if (this.summaryManager !== undefined) {\n        return this.summaryManager.enqueueSummarize(...args);\n      } else {\n        // If we're not the summarizer, and we don't have a summaryManager, we expect that\n        // generateSummaries is turned off. We are throwing instead of returning a failure here,\n        // because it is a misuse of the API rather than an expected failure.\n        throw new UsageError(`Can't summarize, disableSummaries: ${this.summariesDisabled}`);\n      }\n    };\n\n    this.messageAtLastSummary = metadata === null || metadata === void 0 ? void 0 : metadata.message; // Default to false (enabled).\n\n    this.disableIsolatedChannels = (_b = this.runtimeOptions.summaryOptions.disableIsolatedChannels) !== null && _b !== void 0 ? _b : false;\n    this._connected = this.context.connected;\n    this.chunkMap = new Map(chunks);\n    this.handleContext = new ContainerFluidHandleContext(\"\", this);\n    this.mc = loggerToMonitoringContext(ChildLogger.create(this.logger, \"ContainerRuntime\"));\n    this.summariesDisabled = this.isSummariesDisabled();\n    this.heuristicsDisabled = this.isHeuristicsDisabled();\n    this.summarizerClientElectionEnabled = this.isSummarizerClientElectionEnabled();\n    this.maxOpsSinceLastSummary = this.getMaxOpsSinceLastSummary();\n    this.initialSummarizerDelayMs = this.getInitialSummarizerDelayMs();\n    this._aliasingEnabled = ((_c = this.mc.config.getBoolean(useDataStoreAliasingKey)) !== null && _c !== void 0 ? _c : false) || ((_d = runtimeOptions.useDataStoreAliasing) !== null && _d !== void 0 ? _d : false);\n    this._maxOpSizeInBytes = (_e = this.mc.config.getNumber(maxOpSizeInBytesKey)) !== null && _e !== void 0 ? _e : defaultMaxOpSizeInBytes;\n    this.maxConsecutiveReconnects = (_f = this.mc.config.getNumber(maxConsecutiveReconnectsKey)) !== null && _f !== void 0 ? _f : this.defaultMaxConsecutiveReconnects;\n    this._flushMode = runtimeOptions.flushMode;\n    const pendingRuntimeState = context.pendingLocalState;\n    const baseSnapshot = (_g = pendingRuntimeState === null || pendingRuntimeState === void 0 ? void 0 : pendingRuntimeState.baseSnapshot) !== null && _g !== void 0 ? _g : context.baseSnapshot;\n    this.garbageCollector = GarbageCollector.create({\n      runtime: this,\n      gcOptions: this.runtimeOptions.gcOptions,\n      baseSnapshot,\n      baseLogger: this.mc.logger,\n      existing,\n      metadata,\n      isSummarizerClient: this.context.clientDetails.type === summarizerClientType,\n      getNodePackagePath: function () {\n        var _ref = _asyncToGenerator(function* (nodePath) {\n          return _this.getGCNodePackagePath(nodePath);\n        });\n\n        return function getNodePackagePath(_x) {\n          return _ref.apply(this, arguments);\n        };\n      }(),\n      getLastSummaryTimestampMs: () => {\n        var _a;\n\n        return (_a = this.messageAtLastSummary) === null || _a === void 0 ? void 0 : _a.timestamp;\n      },\n      readAndParseBlob: function () {\n        var _ref2 = _asyncToGenerator(function* (id) {\n          return readAndParse(_this.storage, id);\n        });\n\n        return function readAndParseBlob(_x2) {\n          return _ref2.apply(this, arguments);\n        };\n      }()\n    });\n    const loadedFromSequenceNumber = this.deltaManager.initialSequenceNumber;\n    this.summarizerNode = createRootSummarizerNodeWithGC(ChildLogger.create(this.logger, \"SummarizerNode\"),\n    /*#__PURE__*/\n    // Summarize function to call when summarize is called. Summarizer node always tracks summary state.\n    function () {\n      var _ref3 = _asyncToGenerator(function* (fullTree, trackState, telemetryContext) {\n        return _this.summarizeInternal(fullTree, trackState, telemetryContext);\n      });\n\n      return function (_x3, _x4, _x5) {\n        return _ref3.apply(this, arguments);\n      };\n    }(), // Latest change sequence number, no changes since summary applied yet\n    loadedFromSequenceNumber, // Summary reference sequence number, undefined if no summary yet\n    baseSnapshot ? loadedFromSequenceNumber : undefined, {\n      // Must set to false to prevent sending summary handle which would be pointing to\n      // a summary with an older protocol state.\n      canReuseHandle: false,\n      // Must set to true to throw on any data stores failure that was too severe to be handled.\n      // We also are not decoding the base summaries at the root.\n      throwOnFailure: true,\n      // If GC should not run, let the summarizer node know so that it does not track GC state.\n      gcDisabled: !this.garbageCollector.shouldRunGC\n    });\n\n    if (baseSnapshot) {\n      this.summarizerNode.loadBaseSummaryWithoutDifferential(baseSnapshot);\n    }\n\n    this.dataStores = new DataStores(getSummaryForDatastores(baseSnapshot, metadata), this, attachMsg => this.submit(ContainerMessageType.Attach, attachMsg), (id, createParam) => (summarizeInternal, getGCDataFn, getBaseGCDetailsFn) => this.summarizerNode.createChild(summarizeInternal, id, createParam, undefined, getGCDataFn, getBaseGCDetailsFn), id => this.summarizerNode.deleteChild(id), this.mc.logger, /*#__PURE__*/_asyncToGenerator(function* () {\n      return _this.garbageCollector.getBaseGCDetails();\n    }), (path, timestampMs, packagePath) => this.garbageCollector.nodeUpdated(path, \"Changed\", timestampMs, packagePath), new Map(dataStoreAliasMap), this.garbageCollector.writeDataAtRoot);\n    this.blobManager = new BlobManager(this.handleContext, blobManagerSnapshot, () => this.storage, blobId => this.submit(ContainerMessageType.BlobAttach, undefined, undefined, {\n      blobId\n    }), blobPath => this.garbageCollector.nodeUpdated(blobPath, \"Loaded\"), this, this.logger);\n    this.scheduleManager = new ScheduleManager(context.deltaManager, this, ChildLogger.create(this.logger, \"ScheduleManager\"));\n    this.deltaSender = this.deltaManager;\n    this.pendingStateManager = new PendingStateManager({\n      applyStashedOp: this.applyStashedOp.bind(this),\n      clientId: () => this.clientId,\n      close: this.closeFn,\n      connected: () => this.connected,\n      flush: this.flush.bind(this),\n      flushMode: () => this.flushMode,\n      reSubmit: this.reSubmit.bind(this),\n      rollback: this.rollback.bind(this),\n      setFlushMode: mode => this.setFlushMode(mode)\n    }, this._flushMode, pendingRuntimeState === null || pendingRuntimeState === void 0 ? void 0 : pendingRuntimeState.pending);\n    this.context.quorum.on(\"removeMember\", clientId => {\n      this.clearPartialChunks(clientId);\n    });\n    this.summaryCollection = new SummaryCollection(this.deltaManager, this.logger);\n    this.dirtyContainer = this.context.attachState !== AttachState.Attached || this.pendingStateManager.hasPendingMessages();\n    this.context.updateDirtyContainerState(this.dirtyContainer);\n\n    if (this.summariesDisabled) {\n      this.mc.logger.sendTelemetryEvent({\n        eventName: \"SummariesDisabled\"\n      });\n    } else {\n      const orderedClientLogger = ChildLogger.create(this.logger, \"OrderedClientElection\");\n      const orderedClientCollection = new OrderedClientCollection(orderedClientLogger, this.context.deltaManager, this.context.quorum);\n      const orderedClientElectionForSummarizer = new OrderedClientElection(orderedClientLogger, orderedClientCollection, electedSummarizerData !== null && electedSummarizerData !== void 0 ? electedSummarizerData : this.context.deltaManager.lastSequenceNumber, SummarizerClientElection.isClientEligible);\n      this.summarizerClientElection = new SummarizerClientElection(orderedClientLogger, this.summaryCollection, orderedClientElectionForSummarizer, this.maxOpsSinceLastSummary, this.summarizerClientElectionEnabled);\n\n      if (this.context.clientDetails.type === summarizerClientType) {\n        this._summarizer = new Summarizer(\"/_summarizer\", this\n        /* ISummarizerRuntime */\n        , () => this.summaryConfiguration, this\n        /* ISummarizerInternalsProvider */\n        , this.handleContext, this.summaryCollection, /*#__PURE__*/function () {\n          var _ref5 = _asyncToGenerator(function* (runtime) {\n            return RunWhileConnectedCoordinator.create(runtime);\n          });\n\n          return function (_x6) {\n            return _ref5.apply(this, arguments);\n          };\n        }());\n      } else if (SummarizerClientElection.clientDetailsPermitElection(this.context.clientDetails)) {\n        // Only create a SummaryManager and SummarizerClientElection\n        // if summaries are enabled and we are not the summarizer client.\n        const defaultAction = () => {\n          if (this.summaryCollection.opsSinceLastAck > this.maxOpsSinceLastSummary) {\n            this.logger.sendErrorEvent({\n              eventName: \"SummaryStatus:Behind\"\n            }); // unregister default to no log on every op after falling behind\n            // and register summary ack handler to re-register this handler\n            // after successful summary\n\n            this.summaryCollection.once(MessageType.SummaryAck, () => {\n              this.logger.sendTelemetryEvent({\n                eventName: \"SummaryStatus:CaughtUp\"\n              }); // we've caught up, so re-register the default action to monitor for\n              // falling behind, and unregister ourself\n\n              this.summaryCollection.on(\"default\", defaultAction);\n            });\n            this.summaryCollection.off(\"default\", defaultAction);\n          }\n        };\n\n        this.summaryCollection.on(\"default\", defaultAction); // Create the SummaryManager and mark the initial state\n\n        this.summaryManager = new SummaryManager(this.summarizerClientElection, this, // IConnectedState\n        this.summaryCollection, this.logger, this.formRequestSummarizerFn(this.context.loader), new Throttler(60 * 1000, // 60 sec delay window\n        30 * 1000, // 30 sec max delay\n        // throttling function increases exponentially (0ms, 40ms, 80ms, 160ms, etc)\n        formExponentialFn({\n          coefficient: 20,\n          initialDelay: 0\n        })), {\n          initialDelayMs: this.initialSummarizerDelayMs\n        }, this.heuristicsDisabled);\n        this.summaryManager.start();\n      }\n    }\n\n    this.deltaManager.on(\"readonly\", readonly => {\n      // we accumulate ops while being in read-only state.\n      // once user gets write permissions and we have active connection, flush all pending ops.\n      assert(readonly === this.deltaManager.readOnlyInfo.readonly, 0x124\n      /* \"inconsistent readonly property/event state\" */\n      ); // We need to be very careful with when we (re)send pending ops, to ensure that we only send ops\n      // when we either never send an op, or attempted to send it but we know for sure it was not\n      // sequenced by server and will never be sequenced (i.e. was lost)\n      // For loss of connection, we wait for our own \"join\" op and use it a a barrier to know all the\n      // ops that made it from previous connection, before switching clientId and raising \"connected\" event\n      // But with read-only permissions, if we transition between read-only and r/w states while on same\n      // connection, then we have no good signal to tell us when it's safe to send ops we accumulated while\n      // being in read-only state.\n      // For that reason, we support getting to read-only state only when disconnected. This ensures that we\n      // can rely on same safety mechanism and resend ops only when we establish new connection.\n      // This is applicable for read-only permissions (event is raised before connection is properly registered),\n      // but it's an extra requirement for Container.forceReadonly() API\n\n      assert(!readonly || !this.connected, 0x125\n      /* \"Unsafe to transition to read-only state!\" */\n      );\n      this.replayPendingStates();\n    }); // logging hardware telemetry\n\n    logger.sendTelemetryEvent(Object.assign({\n      eventName: \"DeviceSpec\"\n    }, getDeviceSpec()));\n    let loadSummaryNumber; // Get the container creation metadata. For new container, we initialize these. For existing containers,\n    // get the values from the metadata blob.\n\n    if (existing) {\n      this.createContainerMetadata = {\n        createContainerRuntimeVersion: metadata === null || metadata === void 0 ? void 0 : metadata.createContainerRuntimeVersion,\n        createContainerTimestamp: metadata === null || metadata === void 0 ? void 0 : metadata.createContainerTimestamp\n      }; // back-compat 0.59.3000 - Older document may either write summaryCount or not write it at all. If it does\n      // not write it, initialize summaryNumber to 0.\n\n      loadSummaryNumber = (_j = (_h = metadata === null || metadata === void 0 ? void 0 : metadata.summaryNumber) !== null && _h !== void 0 ? _h : metadata === null || metadata === void 0 ? void 0 : metadata.summaryCount) !== null && _j !== void 0 ? _j : 0;\n    } else {\n      this.createContainerMetadata = {\n        createContainerRuntimeVersion: pkgVersion,\n        createContainerTimestamp: Date.now()\n      };\n      loadSummaryNumber = 0;\n    }\n\n    this.nextSummaryNumber = loadSummaryNumber + 1;\n    this.logger.sendTelemetryEvent(Object.assign(Object.assign(Object.assign({\n      eventName: \"ContainerLoadStats\"\n    }, this.createContainerMetadata), this.dataStores.containerLoadStats), {\n      summaryNumber: loadSummaryNumber,\n      summaryFormatVersion: metadata === null || metadata === void 0 ? void 0 : metadata.summaryFormatVersion,\n      disableIsolatedChannels: metadata === null || metadata === void 0 ? void 0 : metadata.disableIsolatedChannels,\n      gcVersion: metadata === null || metadata === void 0 ? void 0 : metadata.gcFeature\n    }));\n    ReportOpPerfTelemetry(this.context.clientId, this.deltaManager, this.logger);\n    BindBatchTracker(this, this.logger);\n    this.opTracker = new OpTracker(this.deltaManager, this.mc.config.getBoolean(disableOpTrackingKey) === true);\n  }\n\n  get IContainerRuntime() {\n    return this;\n  }\n\n  get IFluidRouter() {\n    return this;\n  }\n  /**\n   * Load the stores from a snapshot and returns the runtime.\n   * @param context - Context of the container.\n   * @param registryEntries - Mapping to the stores.\n   * @param requestHandler - Request handlers for the container runtime\n   * @param runtimeOptions - Additional options to be passed to the runtime\n   * @param existing - (optional) When loading from an existing snapshot. Precedes context.existing if provided\n   */\n\n\n  static load(context, registryEntries, requestHandler, runtimeOptions = {}, containerScope = context.scope, existing) {\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c; // If taggedLogger exists, use it. Otherwise, wrap the vanilla logger:\n      // back-compat: Remove the TaggedLoggerAdapter fallback once all the host are using loader > 0.45\n\n\n      const backCompatContext = context;\n      const passLogger = (_a = backCompatContext.taggedLogger) !== null && _a !== void 0 ? _a : new TaggedLoggerAdapter(backCompatContext.logger);\n      const logger = ChildLogger.create(passLogger, undefined, {\n        all: {\n          runtimeVersion: pkgVersion\n        }\n      });\n      const {\n        summaryOptions = {},\n        gcOptions = {},\n        loadSequenceNumberVerification = \"close\",\n        useDataStoreAliasing = false,\n        flushMode = defaultFlushMode,\n        enableOfflineLoad = false\n      } = runtimeOptions;\n      const pendingRuntimeState = context.pendingLocalState;\n      const baseSnapshot = (_b = pendingRuntimeState === null || pendingRuntimeState === void 0 ? void 0 : pendingRuntimeState.baseSnapshot) !== null && _b !== void 0 ? _b : context.baseSnapshot;\n      const storage = !pendingRuntimeState ? context.storage : new SerializedSnapshotStorage(() => {\n        return context.storage;\n      }, pendingRuntimeState.snapshotBlobs);\n      const registry = new FluidDataStoreRegistry(registryEntries);\n\n      const tryFetchBlob = /*#__PURE__*/function () {\n        var _ref6 = _asyncToGenerator(function* (blobName) {\n          const blobId = baseSnapshot === null || baseSnapshot === void 0 ? void 0 : baseSnapshot.blobs[blobName];\n\n          if (baseSnapshot && blobId) {\n            // IContainerContext storage api return type still has undefined in 0.39 package version.\n            // So once we release 0.40 container-defn package we can remove this check.\n            assert(storage !== undefined, 0x1f5\n            /* \"Attached state should have storage\" */\n            );\n            return readAndParse(storage, blobId);\n          }\n        });\n\n        return function tryFetchBlob(_x7) {\n          return _ref6.apply(this, arguments);\n        };\n      }();\n\n      const [chunks, metadata, electedSummarizerData, aliases] = yield Promise.all([tryFetchBlob(chunksBlobName), tryFetchBlob(metadataBlobName), tryFetchBlob(electedSummarizerBlobName), tryFetchBlob(aliasBlobName)]);\n      const loadExisting = existing === true || context.existing === true; // read snapshot blobs needed for BlobManager to load\n\n      const blobManagerSnapshot = yield BlobManager.load(baseSnapshot === null || baseSnapshot === void 0 ? void 0 : baseSnapshot.trees[blobsTreeName], /*#__PURE__*/function () {\n        var _ref7 = _asyncToGenerator(function* (id) {\n          // IContainerContext storage api return type still has undefined in 0.39 package version.\n          // So once we release 0.40 container-defn package we can remove this check.\n          assert(storage !== undefined, 0x256\n          /* \"storage undefined in attached container\" */\n          );\n          return readAndParse(storage, id);\n        });\n\n        return function (_x8) {\n          return _ref7.apply(this, arguments);\n        };\n      }()); // Verify summary runtime sequence number matches protocol sequence number.\n\n      const runtimeSequenceNumber = (_c = metadata === null || metadata === void 0 ? void 0 : metadata.message) === null || _c === void 0 ? void 0 : _c.sequenceNumber; // When we load with pending state, we reuse an old snapshot so we don't expect these numbers to match\n\n      if (!pendingRuntimeState && runtimeSequenceNumber !== undefined) {\n        const protocolSequenceNumber = context.deltaManager.initialSequenceNumber; // Unless bypass is explicitly set, then take action when sequence numbers mismatch.\n\n        if (loadSequenceNumberVerification !== \"bypass\" && runtimeSequenceNumber !== protocolSequenceNumber) {\n          // \"Load from summary, runtime metadata sequenceNumber !== initialSequenceNumber\"\n          const error = new DataCorruptionError( // pre-0.58 error message: SummaryMetadataMismatch\n          \"Summary metadata mismatch\", {\n            runtimeVersion: pkgVersion,\n            runtimeSequenceNumber,\n            protocolSequenceNumber\n          });\n\n          if (loadSequenceNumberVerification === \"log\") {\n            logger.sendErrorEvent({\n              eventName: \"SequenceNumberMismatch\"\n            }, error);\n          } else {\n            context.closeFn(error);\n          }\n        }\n      }\n\n      const runtime = new ContainerRuntime(context, registry, metadata, electedSummarizerData, chunks !== null && chunks !== void 0 ? chunks : [], aliases !== null && aliases !== void 0 ? aliases : [], {\n        summaryOptions,\n        gcOptions,\n        loadSequenceNumberVerification,\n        useDataStoreAliasing,\n        flushMode,\n        enableOfflineLoad\n      }, containerScope, logger, loadExisting, blobManagerSnapshot, storage, requestHandler);\n\n      if (pendingRuntimeState) {\n        yield runtime.processSavedOps(pendingRuntimeState); // delete these once runtime has seen them to save space\n\n        pendingRuntimeState.savedOps = [];\n      }\n\n      yield runtime.getSnapshotBlobs();\n      return runtime;\n    })();\n  }\n\n  get options() {\n    return this.context.options;\n  }\n\n  get clientId() {\n    return this.context.clientId;\n  }\n\n  get clientDetails() {\n    return this.context.clientDetails;\n  }\n\n  get deltaManager() {\n    return this.context.deltaManager;\n  }\n\n  get storage() {\n    return this._storage;\n  }\n\n  get reSubmitFn() {\n    // eslint-disable-next-line @typescript-eslint/unbound-method\n    return this.reSubmit;\n  }\n\n  get closeFn() {\n    return this.context.closeFn;\n  }\n\n  get flushMode() {\n    return this._flushMode;\n  }\n\n  get scope() {\n    return this.containerScope;\n  }\n\n  get IFluidDataStoreRegistry() {\n    return this.registry;\n  }\n\n  get attachState() {\n    return this.context.attachState;\n  }\n\n  get IFluidHandleContext() {\n    return this.handleContext;\n  }\n\n  get connected() {\n    return this._connected;\n  }\n  /** clientId of parent (non-summarizing) container that owns summarizer container */\n\n\n  get summarizerClientId() {\n    var _a;\n\n    return (_a = this.summarizerClientElection) === null || _a === void 0 ? void 0 : _a.electedClientId;\n  }\n\n  get disposed() {\n    return this._disposed;\n  }\n\n  get summarizer() {\n    assert(this._summarizer !== undefined, 0x257\n    /* \"This is not summarizing container\" */\n    );\n    return this._summarizer;\n  }\n\n  isSummariesDisabled() {\n    // back-compat: disableSummaries was moved from ISummaryRuntimeOptions\n    //   to ISummaryConfiguration in 0.60.\n    if (this.runtimeOptions.summaryOptions.disableSummaries === true) {\n      return true;\n    }\n\n    return this.summaryConfiguration.state === \"disabled\";\n  }\n\n  isHeuristicsDisabled() {\n    var _a; // back-compat: disableHeuristics was moved from ISummarizerOptions\n    //   to ISummaryConfiguration in 0.60.\n\n\n    if (((_a = this.runtimeOptions.summaryOptions.summarizerOptions) === null || _a === void 0 ? void 0 : _a.disableHeuristics) === true) {\n      return true;\n    }\n\n    return this.summaryConfiguration.state === \"disableHeuristics\";\n  }\n\n  isSummarizerClientElectionEnabled() {\n    var _a;\n\n    if (this.mc.config.getBoolean(\"Fluid.ContainerRuntime.summarizerClientElection\")) {\n      return (_a = this.mc.config.getBoolean(\"Fluid.ContainerRuntime.summarizerClientElection\")) !== null && _a !== void 0 ? _a : true;\n    } // back-compat: summarizerClientElection was moved from ISummaryRuntimeOptions\n    //   to ISummaryConfiguration in 0.60.\n\n\n    if (this.runtimeOptions.summaryOptions.summarizerClientElection === true) {\n      return true;\n    }\n\n    if (this.summaryConfiguration.state !== \"disabled\") {\n      return this.summaryConfiguration.summarizerClientElection === true;\n    } else {\n      return false;\n    }\n  }\n\n  getMaxOpsSinceLastSummary() {\n    // back-compat: maxOpsSinceLastSummary was moved from ISummaryRuntimeOptions\n    //   to ISummaryConfiguration in 0.60.\n    if (this.runtimeOptions.summaryOptions.maxOpsSinceLastSummary !== undefined) {\n      return this.runtimeOptions.summaryOptions.maxOpsSinceLastSummary;\n    }\n\n    if (this.summaryConfiguration.state !== \"disabled\") {\n      return this.summaryConfiguration.maxOpsSinceLastSummary;\n    } else {\n      return 0;\n    }\n  }\n\n  getInitialSummarizerDelayMs() {\n    // back-compat: initialSummarizerDelayMs was moved from ISummaryRuntimeOptions\n    //   to ISummaryConfiguration in 0.60.\n    if (this.runtimeOptions.summaryOptions.initialSummarizerDelayMs !== undefined) {\n      return this.runtimeOptions.summaryOptions.initialSummarizerDelayMs;\n    }\n\n    if (this.summaryConfiguration.state !== \"disabled\") {\n      return this.summaryConfiguration.initialSummarizerDelayMs;\n    } else {\n      return 0;\n    }\n  }\n\n  dispose(error) {\n    var _a;\n\n    if (this._disposed) {\n      return;\n    }\n\n    this._disposed = true;\n    this.logger.sendTelemetryEvent({\n      eventName: \"ContainerRuntimeDisposed\",\n      isDirty: this.isDirty,\n      lastSequenceNumber: this.deltaManager.lastSequenceNumber,\n      attachState: this.attachState\n    }, error);\n\n    if (this.summaryManager !== undefined) {\n      this.summaryManager.dispose();\n    }\n\n    this.garbageCollector.dispose();\n    (_a = this._summarizer) === null || _a === void 0 ? void 0 : _a.dispose();\n    this.dataStores.dispose();\n    this.pendingStateManager.dispose();\n    this.emit(\"dispose\");\n    this.removeAllListeners();\n  }\n\n  get IFluidTokenProvider() {\n    var _a;\n\n    if ((_a = this.options) === null || _a === void 0 ? void 0 : _a.intelligence) {\n      // eslint-disable-next-line @typescript-eslint/consistent-type-assertions\n      return {\n        intelligence: this.options.intelligence\n      };\n    }\n\n    return undefined;\n  }\n  /**\n   * Notifies this object about the request made to the container.\n   * @param request - Request made to the handler.\n   */\n\n\n  request(request) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      try {\n        const parser = RequestParser.create(request);\n        const id = parser.pathParts[0];\n\n        if (id === \"_summarizer\" && parser.pathParts.length === 1) {\n          if (_this2._summarizer !== undefined) {\n            return {\n              status: 200,\n              mimeType: \"fluid/object\",\n              value: _this2.summarizer\n            };\n          }\n\n          return create404Response(request);\n        }\n\n        if (_this2.requestHandler !== undefined) {\n          return _this2.requestHandler(parser, _this2);\n        }\n\n        return create404Response(request);\n      } catch (error) {\n        return exceptionToResponse(error);\n      }\n    })();\n  }\n  /**\n   * Resolves URI representing handle\n   * @param request - Request made to the handler.\n   */\n\n\n  resolveHandle(request) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      try {\n        const requestParser = RequestParser.create(request);\n        const id = requestParser.pathParts[0];\n\n        if (id === \"_channels\") {\n          return _this3.resolveHandle(requestParser.createSubRequest(1));\n        }\n\n        if (id === BlobManager.basePath && requestParser.isLeaf(2)) {\n          const handle = yield _this3.blobManager.getBlob(requestParser.pathParts[1]);\n\n          if (handle) {\n            return {\n              status: 200,\n              mimeType: \"fluid/object\",\n              value: handle.get()\n            };\n          } else {\n            return create404Response(request);\n          }\n        } else if (requestParser.pathParts.length > 0) {\n          const dataStore = yield _this3.getDataStoreFromRequest(id, request);\n          const subRequest = requestParser.createSubRequest(1); // We always expect createSubRequest to include a leading slash, but asserting here to protect against\n          // unintentionally modifying the url if that changes.\n\n          assert(subRequest.url.startsWith(\"/\"), 0x126\n          /* \"Expected createSubRequest url to include a leading slash\" */\n          );\n          return dataStore.IFluidRouter.request(subRequest);\n        }\n\n        return create404Response(request);\n      } catch (error) {\n        return exceptionToResponse(error);\n      }\n    })();\n  }\n\n  internalId(maybeAlias) {\n    var _a;\n\n    return (_a = this.dataStores.aliases().get(maybeAlias)) !== null && _a !== void 0 ? _a : maybeAlias;\n  }\n\n  getDataStoreFromRequest(id, request) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      const wait = typeof ((_a = request.headers) === null || _a === void 0 ? void 0 : _a[RuntimeHeaders.wait]) === \"boolean\" ? (_b = request.headers) === null || _b === void 0 ? void 0 : _b[RuntimeHeaders.wait] : true;\n\n      const internalId = _this4.internalId(id);\n\n      const dataStoreContext = yield _this4.dataStores.getDataStore(internalId, wait);\n      /**\n       * If GC should run and this an external app request with \"externalRequest\" header, we need to return\n       * an error if the data store being requested is marked as unreferenced as per the data store's base\n       * GC data.\n       *\n       * This is a workaround to handle scenarios where a data store shared with an external app is deleted\n       * and marked as unreferenced by GC. Returning an error will fail to load the data store for the app.\n       */\n\n      if (((_c = request.headers) === null || _c === void 0 ? void 0 : _c[RuntimeHeaders.externalRequest]) && _this4.garbageCollector.shouldRunGC) {\n        // The data store is referenced if used routes in the base summary has a route to self.\n        // Older documents may not have used routes in the summary. They are considered referenced.\n        const usedRoutes = (yield dataStoreContext.getBaseGCDetails()).usedRoutes;\n\n        if (!(usedRoutes === undefined || usedRoutes.includes(\"\") || usedRoutes.includes(\"/\"))) {\n          throw responseToException(create404Response(request), request);\n        }\n      }\n\n      const dataStoreChannel = yield dataStoreContext.realize(); // Remove query params, leading and trailing slashes from the url. This is done to make sure the format is\n      // the same as GC nodes id.\n\n      const urlWithoutQuery = trimLeadingAndTrailingSlashes(request.url.split(\"?\")[0]);\n\n      _this4.garbageCollector.nodeUpdated(`/${urlWithoutQuery}`, \"Loaded\", undefined\n      /* timestampMs */\n      , dataStoreContext.packagePath, request === null || request === void 0 ? void 0 : request.headers);\n\n      return dataStoreChannel;\n    })();\n  }\n  /** Adds the container's metadata to the given summary tree. */\n\n\n  addMetadataToSummary(summaryTree) {\n    var _a;\n\n    const metadata = Object.assign(Object.assign(Object.assign(Object.assign({}, this.createContainerMetadata), {\n      // back-compat 0.59.3000: This is renamed to summaryNumber. Can be removed when 0.59.3000 saturates.\n      summaryCount: this.nextSummaryNumber,\n      // Increment the summary number for the next summary that will be generated.\n      summaryNumber: this.nextSummaryNumber++,\n      summaryFormatVersion: 1,\n      disableIsolatedChannels: this.disableIsolatedChannels || undefined\n    }), this.garbageCollector.getMetadata()), {\n      // The last message processed at the time of summary. If there are no new messages, use the message from the\n      // last summary.\n      message: (_a = extractSummaryMetadataMessage(this.deltaManager.lastMessage)) !== null && _a !== void 0 ? _a : this.messageAtLastSummary\n    });\n    addBlobToSummary(summaryTree, metadataBlobName, JSON.stringify(metadata));\n  }\n\n  addContainerStateToSummary(summaryTree, fullTree, trackState, telemetryContext) {\n    var _a;\n\n    this.addMetadataToSummary(summaryTree);\n\n    if (this.chunkMap.size > 0) {\n      const content = JSON.stringify([...this.chunkMap]);\n      addBlobToSummary(summaryTree, chunksBlobName, content);\n    }\n\n    const dataStoreAliases = this.dataStores.aliases();\n\n    if (dataStoreAliases.size > 0) {\n      addBlobToSummary(summaryTree, aliasBlobName, JSON.stringify([...dataStoreAliases]));\n    }\n\n    if (this.summarizerClientElection) {\n      const electedSummarizerContent = JSON.stringify((_a = this.summarizerClientElection) === null || _a === void 0 ? void 0 : _a.serialize());\n      addBlobToSummary(summaryTree, electedSummarizerBlobName, electedSummarizerContent);\n    }\n\n    const blobManagerSummary = this.blobManager.summarize(); // Some storage (like git) doesn't allow empty tree, so we can omit it.\n    // and the blob manager can handle the tree not existing when loading\n\n    if (Object.keys(blobManagerSummary.summary.tree).length > 0) {\n      addTreeToSummary(summaryTree, blobsTreeName, blobManagerSummary);\n    }\n\n    if (this.garbageCollector.writeDataAtRoot) {\n      const gcSummary = this.garbageCollector.summarize(fullTree, trackState, telemetryContext);\n\n      if (gcSummary !== undefined) {\n        addSummarizeResultToSummary(summaryTree, gcTreeKey, gcSummary);\n      }\n    }\n  } // Track how many times the container tries to reconnect with pending messages.\n  // This happens when the connection state is changed and we reset the counter\n  // when we are able to process a local op or when there are no pending messages.\n  // If this counter reaches a max, it's a good indicator that the container\n  // is not making progress and it is stuck in a retry loop.\n\n\n  shouldContinueReconnecting() {\n    if (this.maxConsecutiveReconnects <= 0) {\n      // Feature disabled, we never stop reconnecting\n      return true;\n    }\n\n    if (!this.pendingStateManager.hasPendingMessages()) {\n      // If there are no pending messages, we can always reconnect\n      this.resetReconnectCount();\n      return true;\n    }\n\n    if (this.consecutiveReconnects === Math.floor(this.maxConsecutiveReconnects / 2)) {\n      // If we're halfway through the max reconnects, send an event in order\n      // to better identify false positives, if any. If the rate of this event\n      // matches Container Close count below, we can safely cut down\n      // maxConsecutiveReconnects to half.\n      this.mc.logger.sendTelemetryEvent({\n        eventName: \"ReconnectsWithNoProgress\",\n        attempts: this.consecutiveReconnects,\n        pendingMessages: this.pendingStateManager.pendingMessagesCount\n      });\n    }\n\n    return this.consecutiveReconnects < this.maxConsecutiveReconnects;\n  }\n\n  resetReconnectCount() {\n    this.consecutiveReconnects = 0;\n  }\n\n  replayPendingStates() {\n    // We need to be able to send ops to replay states\n    if (!this.canSendOps()) {\n      return;\n    } // We need to temporary clear the dirty flags and disable\n    // dirty state change events to detect whether replaying ops\n    // has any effect.\n    // Save the old state, reset to false, disable event emit\n\n\n    const oldState = this.dirtyContainer;\n    this.dirtyContainer = false;\n    assert(this.emitDirtyDocumentEvent, 0x127\n    /* \"dirty document event not set on replay\" */\n    );\n    this.emitDirtyDocumentEvent = false;\n    let newState;\n\n    try {\n      // replay the ops\n      this.pendingStateManager.replayPendingStates();\n    } finally {\n      // Save the new start and restore the old state, re-enable event emit\n      newState = this.dirtyContainer;\n      this.dirtyContainer = oldState;\n      this.emitDirtyDocumentEvent = true;\n    } // Officially transition from the old state to the new state.\n\n\n    this.updateDocumentDirtyState(newState);\n  }\n\n  applyStashedOp(type, op) {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      switch (type) {\n        case ContainerMessageType.FluidDataStoreOp:\n          return _this5.dataStores.applyStashedOp(op);\n\n        case ContainerMessageType.Attach:\n          return _this5.dataStores.applyStashedAttachOp(op);\n\n        case ContainerMessageType.Alias:\n        case ContainerMessageType.BlobAttach:\n          return;\n\n        case ContainerMessageType.ChunkedOp:\n          throw new Error(\"chunkedOp not expected here\");\n\n        case ContainerMessageType.Rejoin:\n          throw new Error(\"rejoin not expected here\");\n\n        default:\n          unreachableCase(type, `Unknown ContainerMessageType: ${type}`);\n      }\n    })();\n  }\n\n  setConnectionState(connected, clientId) {\n    this.verifyNotClosed(); // There might be no change of state due to Container calling this API after loading runtime.\n\n    const changeOfState = this._connected !== connected;\n    const reconnection = changeOfState && connected;\n    this._connected = connected;\n\n    if (!connected) {\n      this._perfSignalData.signalsLost = 0;\n      this._perfSignalData.signalTimestamp = 0;\n      this._perfSignalData.trackingSignalSequenceNumber = undefined;\n    }\n\n    if (reconnection) {\n      this.consecutiveReconnects++;\n\n      if (!this.shouldContinueReconnecting()) {\n        this.closeFn( // pre-0.58 error message: MaxReconnectsWithNoProgress\n        DataProcessingError.create(\"Runtime detected too many reconnects with no progress syncing local ops\", \"setConnectionState\", undefined, {\n          dataLoss: 1,\n          attempts: this.consecutiveReconnects,\n          pendingMessages: this.pendingStateManager.pendingMessagesCount\n        }));\n        return;\n      }\n    }\n\n    if (changeOfState) {\n      this.replayPendingStates();\n    }\n\n    this.dataStores.setConnectionState(connected, clientId);\n    raiseConnectedEvent(this.mc.logger, this, connected, clientId);\n  }\n\n  process(messageArg, local) {\n    var _a, _b;\n\n    this.verifyNotClosed(); // If it's not message for runtime, bail out right away.\n\n    if (!isUnpackedRuntimeMessage(messageArg)) {\n      return;\n    }\n\n    if ((_a = this.mc.config.getBoolean(\"enableOfflineLoad\")) !== null && _a !== void 0 ? _a : this.runtimeOptions.enableOfflineLoad) {\n      this.savedOps.push(messageArg);\n    } // Do shallow copy of message, as methods below will modify it.\n    // There might be multiple container instances receiving same message\n    // We do not need to make deep copy, as each layer will just replace message.content itself,\n    // but would not modify contents details\n\n\n    let message = Object.assign({}, messageArg); // Surround the actual processing of the operation with messages to the schedule manager indicating\n    // the beginning and end. This allows it to emit appropriate events and/or pause the processing of new\n    // messages once a batch has been fully processed.\n\n    this.scheduleManager.beforeOpProcessing(message);\n\n    try {\n      message = unpackRuntimeMessage(message); // Chunk processing must come first given that we will transform the message to the unchunked version\n      // once all pieces are available\n\n      message = this.processRemoteChunkedMessage(message);\n      let localOpMetadata;\n\n      if (local) {\n        // Call the PendingStateManager to process local messages.\n        // Do not process local chunked ops until all pieces are available.\n        if (message.type !== ContainerMessageType.ChunkedOp) {\n          localOpMetadata = this.pendingStateManager.processPendingLocalMessage(message);\n        }\n      } // If there are no more pending messages after processing a local message,\n      // the document is no longer dirty.\n\n\n      if (!this.pendingStateManager.hasPendingMessages()) {\n        this.updateDocumentDirtyState(false);\n      }\n\n      switch (message.type) {\n        case ContainerMessageType.Attach:\n          this.dataStores.processAttachMessage(message, local);\n          break;\n\n        case ContainerMessageType.Alias:\n          this.processAliasMessage(message, localOpMetadata, local);\n          break;\n\n        case ContainerMessageType.FluidDataStoreOp:\n          this.dataStores.processFluidDataStoreOp(message, local, localOpMetadata);\n          break;\n\n        case ContainerMessageType.BlobAttach:\n          assert((_b = message === null || message === void 0 ? void 0 : message.metadata) === null || _b === void 0 ? void 0 : _b.blobId, 0x12a\n          /* \"Missing blob id on metadata\" */\n          );\n          this.blobManager.processBlobAttachOp(message.metadata.blobId, local);\n          break;\n\n        default:\n      }\n\n      this.emit(\"op\", message);\n      this.scheduleManager.afterOpProcessing(undefined, message);\n\n      if (local) {\n        // If we have processed a local op, this means that the container is\n        // making progress and we can reset the counter for how many times\n        // we have consecutively replayed the pending states\n        this.resetReconnectCount();\n      }\n    } catch (e) {\n      this.scheduleManager.afterOpProcessing(e, message);\n      throw e;\n    }\n  }\n\n  processAliasMessage(message, localOpMetadata, local) {\n    this.dataStores.processAliasMessage(message, localOpMetadata, local);\n  }\n  /**\n   * Emits the Signal event and update the perf signal data.\n   * @param clientSignalSequenceNumber - is the client signal sequence number to be uploaded.\n   */\n\n\n  sendSignalTelemetryEvent(clientSignalSequenceNumber) {\n    const duration = Date.now() - this._perfSignalData.signalTimestamp;\n\n    this.logger.sendPerformanceEvent({\n      eventName: \"SignalLatency\",\n      duration,\n      signalsLost: this._perfSignalData.signalsLost\n    });\n    this._perfSignalData.signalsLost = 0;\n    this._perfSignalData.signalTimestamp = 0;\n  }\n\n  processSignal(message, local) {\n    const envelope = message.content;\n    const transformed = {\n      clientId: message.clientId,\n      content: envelope.contents.content,\n      type: envelope.contents.type\n    }; // Only collect signal telemetry for messages sent by the current client.\n\n    if (message.clientId === this.clientId && this.connected) {\n      // Check to see if the signal was lost.\n      if (this._perfSignalData.trackingSignalSequenceNumber !== undefined && envelope.clientSignalSequenceNumber > this._perfSignalData.trackingSignalSequenceNumber) {\n        this._perfSignalData.signalsLost++;\n        this._perfSignalData.trackingSignalSequenceNumber = undefined;\n        this.logger.sendErrorEvent({\n          eventName: \"SignalLost\",\n          type: envelope.contents.type,\n          signalsLost: this._perfSignalData.signalsLost,\n          trackingSequenceNumber: this._perfSignalData.trackingSignalSequenceNumber,\n          clientSignalSequenceNumber: envelope.clientSignalSequenceNumber\n        });\n      } else if (envelope.clientSignalSequenceNumber === this._perfSignalData.trackingSignalSequenceNumber) {\n        this.sendSignalTelemetryEvent(envelope.clientSignalSequenceNumber);\n        this._perfSignalData.trackingSignalSequenceNumber = undefined;\n      }\n    }\n\n    if (envelope.address === undefined) {\n      // No address indicates a container signal message.\n      this.emit(\"signal\", transformed, local);\n      return;\n    }\n\n    this.dataStores.processSignal(envelope.address, transformed, local);\n  }\n\n  getRootDataStore(id, wait = true) {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      const internalId = _this6.internalId(id);\n\n      const context = yield _this6.dataStores.getDataStore(internalId, wait);\n      assert(yield context.isRoot(), 0x12b\n      /* \"did not get root data store\" */\n      );\n      return context.realize();\n    })();\n  }\n\n  setFlushMode(mode) {\n    if (mode === this._flushMode) {\n      return;\n    }\n\n    this.mc.logger.sendTelemetryEvent({\n      eventName: \"FlushMode Updated\",\n      old: this._flushMode,\n      new: mode\n    }); // Flush any pending batches if switching to immediate\n\n    if (mode === FlushMode.Immediate) {\n      this.flush();\n    }\n\n    this._flushMode = mode; // Let the PendingStateManager know that FlushMode has been updated.\n\n    this.pendingStateManager.onFlushModeUpdated(mode);\n  }\n\n  flush() {\n    assert(this._orderSequentiallyCalls === 0, 0x24c\n    /* \"Cannot call `flush()` from `orderSequentially`'s callback\" */\n    );\n\n    if (!this.deltaSender) {\n      return;\n    } // Let the PendingStateManager know that there was an attempt to flush messages.\n    // Note that this should happen before the `this.needsFlush` check below because in the scenario where we are\n    // not connected, `this.needsFlush` will be false but the PendingStateManager might have pending messages and\n    // hence needs to track this.\n\n\n    this.pendingStateManager.onFlush(); // If flush has already been called then exit early\n\n    if (!this.needsFlush) {\n      return;\n    }\n\n    this.needsFlush = false; // Did we disconnect in the middle of turn-based batch?\n    // If so, do nothing, as pending state manager will resubmit it correctly on reconnect.\n\n    if (!this.canSendOps()) {\n      return;\n    }\n\n    return this.deltaSender.flush();\n  }\n\n  orderSequentially(callback) {\n    // If flush mode is already TurnBased we are either\n    // nested in another orderSequentially, or\n    // the app is flushing manually, in which\n    // case this invocation doesn't own\n    // flushing.\n    if (this.flushMode === FlushMode.TurnBased) {\n      this.trackOrderSequentiallyCalls(callback);\n      return;\n    }\n\n    const savedFlushMode = this.flushMode;\n    this.setFlushMode(FlushMode.TurnBased);\n\n    try {\n      this.trackOrderSequentiallyCalls(callback);\n      this.flush();\n    } finally {\n      this.setFlushMode(savedFlushMode);\n    }\n  }\n\n  trackOrderSequentiallyCalls(callback) {\n    let checkpoint;\n\n    if (this.mc.config.getBoolean(\"Fluid.ContainerRuntime.EnableRollback\")) {\n      checkpoint = this.pendingStateManager.checkpoint();\n    }\n\n    try {\n      this._orderSequentiallyCalls++;\n      callback();\n    } catch (error) {\n      if (checkpoint) {\n        // This will throw and close the container if rollback fails\n        checkpoint.rollback();\n      } else {\n        // pre-0.58 error message: orderSequentiallyCallbackException\n        this.closeFn(new GenericError(\"orderSequentially callback exception\", error));\n      }\n\n      throw error; // throw the original error for the consumer of the runtime\n    } finally {\n      this._orderSequentiallyCalls--;\n    }\n  }\n\n  createDataStore(pkg) {\n    var _this7 = this;\n\n    return _asyncToGenerator(function* () {\n      const internalId = uuid();\n      return channelToDataStore(yield _this7._createDataStore(pkg, false\n      /* isRoot */\n      , internalId), internalId, _this7, _this7.dataStores, _this7.mc.logger);\n    })();\n  }\n  /**\n   * Creates a root datastore directly with a user generated id and attaches it to storage.\n   * It is vulnerable to name collisions and should not be used.\n   *\n   * This method will be removed. See #6465.\n   */\n\n\n  createRootDataStoreLegacy(pkg, rootDataStoreId) {\n    var _this8 = this;\n\n    return _asyncToGenerator(function* () {\n      const fluidDataStore = yield _this8._createDataStore(pkg, true\n      /* isRoot */\n      , rootDataStoreId); // back-compat 0.59.1000 - makeVisibleAndAttachGraph was added in this version to IFluidDataStoreChannel. For\n      // older versions, we still have to call bindToContext.\n\n      if (fluidDataStore.makeVisibleAndAttachGraph !== undefined) {\n        fluidDataStore.makeVisibleAndAttachGraph();\n      } else {\n        fluidDataStore.bindToContext();\n      }\n\n      return fluidDataStore;\n    })();\n  }\n  /**\n   * @deprecated - will be removed in an upcoming release. See #9660.\n   */\n\n\n  createRootDataStore(pkg, rootDataStoreId) {\n    var _this9 = this;\n\n    return _asyncToGenerator(function* () {\n      if (rootDataStoreId.includes(\"/\")) {\n        throw new UsageError(`Id cannot contain slashes: '${rootDataStoreId}'`);\n      }\n\n      return _this9._aliasingEnabled === true ? _this9.createAndAliasDataStore(pkg, rootDataStoreId) : _this9.createRootDataStoreLegacy(pkg, rootDataStoreId);\n    })();\n  }\n  /**\n   * Creates a data store then attempts to alias it.\n   * If aliasing fails, it will raise an exception.\n   *\n   * This method will be removed. See #6465.\n   *\n   * @param pkg - Package name of the data store\n   * @param alias - Alias to be assigned to the data store\n   * @param props - Properties for the data store\n   * @returns - An aliased data store which can can be found / loaded by alias.\n   */\n\n\n  createAndAliasDataStore(pkg, alias, props) {\n    var _this10 = this;\n\n    return _asyncToGenerator(function* () {\n      const internalId = uuid();\n      const dataStore = yield _this10._createDataStore(pkg, false\n      /* isRoot */\n      , internalId, props);\n      const aliasedDataStore = channelToDataStore(dataStore, internalId, _this10, _this10.dataStores, _this10.mc.logger);\n      const result = yield aliasedDataStore.trySetAlias(alias);\n\n      if (result !== \"Success\") {\n        throw new GenericError(\"dataStoreAliasFailure\", undefined\n        /* error */\n        , {\n          alias: {\n            value: alias,\n            tag: TelemetryDataTag.UserData\n          },\n          internalId: {\n            value: internalId,\n            tag: TelemetryDataTag.PackageData\n          },\n          aliasResult: result\n        });\n      }\n\n      return aliasedDataStore;\n    })();\n  }\n\n  createDetachedRootDataStore(pkg, rootDataStoreId) {\n    if (rootDataStoreId.includes(\"/\")) {\n      throw new UsageError(`Id cannot contain slashes: '${rootDataStoreId}'`);\n    }\n\n    return this.dataStores.createDetachedDataStoreCore(pkg, true, rootDataStoreId);\n  }\n\n  createDetachedDataStore(pkg) {\n    return this.dataStores.createDetachedDataStoreCore(pkg, false);\n  }\n  /**\n   * Creates a possibly root datastore directly with a possibly user generated id and attaches it to storage.\n   * It is vulnerable to name collisions if both aforementioned conditions are true, and should not be used.\n   *\n   * This method will be removed. See #6465.\n   */\n\n\n  _createDataStoreWithPropsLegacy(pkg, props, id = uuid(), isRoot = false) {\n    var _this11 = this;\n\n    return _asyncToGenerator(function* () {\n      const fluidDataStore = yield _this11.dataStores._createFluidDataStoreContext(Array.isArray(pkg) ? pkg : [pkg], id, isRoot, props).realize();\n\n      if (isRoot) {\n        // back-compat 0.59.1000 - makeVisibleAndAttachGraph was added in this version to IFluidDataStoreChannel.\n        // For older versions, we still have to call bindToContext.\n        if (fluidDataStore.makeVisibleAndAttachGraph !== undefined) {\n          fluidDataStore.makeVisibleAndAttachGraph();\n        } else {\n          fluidDataStore.bindToContext();\n        }\n\n        _this11.logger.sendTelemetryEvent({\n          eventName: \"Root datastore with props\",\n          hasProps: props !== undefined\n        });\n      }\n\n      return channelToDataStore(fluidDataStore, id, _this11, _this11.dataStores, _this11.mc.logger);\n    })();\n  }\n\n  _createDataStoreWithProps(pkg, props, id = uuid(), isRoot = false) {\n    var _this12 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this12._aliasingEnabled === true && isRoot ? _this12.createAndAliasDataStore(pkg, id, props) : _this12._createDataStoreWithPropsLegacy(pkg, props, id, isRoot);\n    })();\n  }\n\n  _createDataStore(pkg, isRoot, id = uuid(), props) {\n    var _this13 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this13.dataStores._createFluidDataStoreContext(Array.isArray(pkg) ? pkg : [pkg], id, isRoot, props).realize();\n    })();\n  }\n\n  canSendOps() {\n    return this.connected && !this.deltaManager.readOnlyInfo.readonly;\n  }\n\n  getQuorum() {\n    return this.context.quorum;\n  }\n\n  getAudience() {\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    return this.context.audience;\n  }\n  /**\n   * Returns true of container is dirty, i.e. there are some pending local changes that\n   * either were not sent out to delta stream or were not yet acknowledged.\n   */\n\n\n  get isDirty() {\n    return this.dirtyContainer;\n  }\n\n  isContainerMessageDirtyable(type, contents) {\n    // For legacy purposes, exclude the old built-in AgentScheduler from dirty consideration as a special-case.\n    // Ultimately we should have no special-cases from the ContainerRuntime's perspective.\n    if (type === ContainerMessageType.Attach) {\n      const attachMessage = contents;\n\n      if (attachMessage.id === agentSchedulerId) {\n        return false;\n      }\n    } else if (type === ContainerMessageType.FluidDataStoreOp) {\n      const envelope = contents;\n\n      if (envelope.address === agentSchedulerId) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  createNewSignalEnvelope(address, type, content) {\n    const newSequenceNumber = ++this._perfSignalData.signalSequenceNumber;\n    const newEnvelope = {\n      address,\n      clientSignalSequenceNumber: newSequenceNumber,\n      contents: {\n        type,\n        content\n      }\n    }; // We should not track any signals in case we already have a tracking number.\n\n    if (newSequenceNumber % this.defaultTelemetrySignalSampleCount === 1 && this._perfSignalData.trackingSignalSequenceNumber === undefined) {\n      this._perfSignalData.signalTimestamp = Date.now();\n      this._perfSignalData.trackingSignalSequenceNumber = newSequenceNumber;\n    }\n\n    return newEnvelope;\n  }\n  /**\n   * Submits the signal to be sent to other clients.\n   * @param type - Type of the signal.\n   * @param content - Content of the signal.\n   */\n\n\n  submitSignal(type, content) {\n    this.verifyNotClosed();\n    const envelope = this.createNewSignalEnvelope(undefined\n    /* address */\n    , type, content);\n    return this.context.submitSignalFn(envelope);\n  }\n\n  submitDataStoreSignal(address, type, content) {\n    const envelope = this.createNewSignalEnvelope(address, type, content);\n    return this.context.submitSignalFn(envelope);\n  }\n\n  setAttachState(attachState) {\n    if (attachState === AttachState.Attaching) {\n      assert(this.attachState === AttachState.Attaching, 0x12d\n      /* \"Container Context should already be in attaching state\" */\n      );\n    } else {\n      assert(this.attachState === AttachState.Attached, 0x12e\n      /* \"Container Context should already be in attached state\" */\n      );\n      this.emit(\"attached\");\n    }\n\n    if (attachState === AttachState.Attached && !this.pendingStateManager.hasPendingMessages()) {\n      this.updateDocumentDirtyState(false);\n    }\n\n    this.dataStores.setAttachState(attachState);\n  }\n  /**\n   * Create a summary. Used when attaching or serializing a detached container.\n   *\n   * @param blobRedirectTable - A table passed during the attach process. While detached, blob upload is supported\n   * using IDs generated locally. After attach, these IDs cannot be used, so this table maps the old local IDs to the\n   * new storage IDs so requests can be redirected.\n   * @param telemetryContext - summary data passed through the layers for telemetry purposes\n   */\n\n\n  createSummary(blobRedirectTable, telemetryContext) {\n    if (blobRedirectTable) {\n      this.blobManager.setRedirectTable(blobRedirectTable);\n    }\n\n    const summarizeResult = this.dataStores.createSummary(telemetryContext);\n\n    if (!this.disableIsolatedChannels) {\n      // Wrap data store summaries in .channels subtree.\n      wrapSummaryInChannelsTree(summarizeResult);\n    }\n\n    this.addContainerStateToSummary(summarizeResult, true\n    /* fullTree */\n    , false\n    /* trackState */\n    , telemetryContext);\n    return summarizeResult.summary;\n  }\n\n  getAbsoluteUrl(relativeUrl) {\n    var _this14 = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this14.context.getAbsoluteUrl === undefined) {\n        throw new Error(\"Driver does not implement getAbsoluteUrl\");\n      }\n\n      if (_this14.attachState !== AttachState.Attached) {\n        return undefined;\n      }\n\n      return _this14.context.getAbsoluteUrl(relativeUrl);\n    })();\n  }\n\n  summarizeInternal(fullTree, trackState, telemetryContext) {\n    var _this15 = this;\n\n    return _asyncToGenerator(function* () {\n      const summarizeResult = yield _this15.dataStores.summarize(fullTree, trackState, telemetryContext);\n      let pathPartsForChildren;\n\n      if (!_this15.disableIsolatedChannels) {\n        // Wrap data store summaries in .channels subtree.\n        wrapSummaryInChannelsTree(summarizeResult);\n        pathPartsForChildren = [channelsTreeName];\n      }\n\n      _this15.addContainerStateToSummary(summarizeResult, fullTree, trackState, telemetryContext);\n\n      return Object.assign(Object.assign({}, summarizeResult), {\n        id: \"\",\n        pathPartsForChildren\n      });\n    })();\n  }\n  /**\n   * Returns a summary of the runtime at the current sequence number.\n   */\n\n\n  summarize(options) {\n    var _this16 = this;\n\n    return _asyncToGenerator(function* () {\n      _this16.verifyNotClosed();\n\n      const {\n        fullTree = false,\n        trackState = true,\n        summaryLogger = _this16.mc.logger,\n        runGC = _this16.garbageCollector.shouldRunGC,\n        runSweep,\n        fullGC\n      } = options;\n      let gcStats;\n\n      if (runGC) {\n        gcStats = yield _this16.collectGarbage({\n          logger: summaryLogger,\n          runSweep,\n          fullGC\n        });\n      }\n\n      const telemetryContext = new TelemetryContext();\n      const {\n        stats,\n        summary\n      } = yield _this16.summarizerNode.summarize(fullTree, trackState, telemetryContext);\n\n      _this16.logger.sendTelemetryEvent({\n        eventName: \"SummarizeTelemetry\",\n        details: telemetryContext.serialize()\n      });\n\n      assert(summary.type === SummaryType.Tree, 0x12f\n      /* \"Container Runtime's summarize should always return a tree\" */\n      );\n      return {\n        stats,\n        summary,\n        gcStats\n      };\n    })();\n  }\n  /**\n   * Implementation of IGarbageCollectionRuntime::updateStateBeforeGC.\n   * Before GC runs, called by the garbage collector to update any pending GC state. This is mainly used to notify\n   * the garbage collector of references detected since the last GC run. Most references are notified immediately\n   * but there can be some for which async operation is required (such as detecting new root data stores).\n   */\n\n\n  updateStateBeforeGC() {\n    var _this17 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this17.dataStores.updateStateBeforeGC();\n    })();\n  }\n  /**\n   * Implementation of IGarbageCollectionRuntime::getGCData.\n   * Generates and returns the GC data for this container.\n   * @param fullGC - true to bypass optimizations and force full generation of GC data.\n   */\n\n\n  getGCData(fullGC) {\n    var _this18 = this;\n\n    return _asyncToGenerator(function* () {\n      const builder = new GCDataBuilder();\n      const dsGCData = yield _this18.dataStores.getGCData(fullGC);\n      builder.addNodes(dsGCData.gcNodes);\n\n      const blobsGCData = _this18.blobManager.getGCData(fullGC);\n\n      builder.addNodes(blobsGCData.gcNodes);\n      return builder.getGCData();\n    })();\n  }\n  /**\n   * Implementation of IGarbageCollectionRuntime::updateUsedRoutes.\n   * After GC has run, called to notify this container's nodes of routes that are used in it.\n   * @param usedRoutes - The routes that are used in all nodes in this Container.\n   * @param gcTimestamp - The time when GC was run that generated these used routes. If any node node becomes\n   * unreferenced as part of this GC run, this should be used to update the time when it happens.\n   */\n\n\n  updateUsedRoutes(usedRoutes, gcTimestamp) {\n    // Update our summarizer node's used routes. Updating used routes in summarizer node before\n    // summarizing is required and asserted by the the summarizer node. We are the root and are\n    // always referenced, so the used routes is only self-route (empty string).\n    this.summarizerNode.updateUsedRoutes([\"\"]);\n    const dataStoreUsedRoutes = [];\n\n    for (const route of usedRoutes) {\n      if (route.split(\"/\")[1] !== BlobManager.basePath) {\n        dataStoreUsedRoutes.push(route);\n      }\n    }\n\n    return this.dataStores.updateUsedRoutes(dataStoreUsedRoutes, gcTimestamp);\n  }\n  /**\n   * When running GC in test mode, this is called to delete objects whose routes are unused. This enables testing\n   * scenarios with accessing deleted content.\n   * @param unusedRoutes - The routes that are unused in all data stores in this Container.\n   */\n\n\n  deleteUnusedRoutes(unusedRoutes) {\n    const blobManagerUnusedRoutes = [];\n    const dataStoreUnusedRoutes = [];\n\n    for (const route of unusedRoutes) {\n      if (this.isBlobPath(route)) {\n        blobManagerUnusedRoutes.push(route);\n      } else {\n        dataStoreUnusedRoutes.push(route);\n      }\n    }\n\n    this.blobManager.deleteUnusedRoutes(blobManagerUnusedRoutes);\n    this.dataStores.deleteUnusedRoutes(dataStoreUnusedRoutes);\n  }\n  /**\n   * Returns a server generated referenced timestamp to be used to track unreferenced nodes by GC.\n   */\n\n\n  getCurrentReferenceTimestampMs() {\n    var _a, _b, _c; // Use the timestamp of the last message seen by this client as that is server generated. If no messages have\n    // been processed, use the timestamp of the message from the last summary.\n\n\n    return (_b = (_a = this.deltaManager.lastMessage) === null || _a === void 0 ? void 0 : _a.timestamp) !== null && _b !== void 0 ? _b : (_c = this.messageAtLastSummary) === null || _c === void 0 ? void 0 : _c.timestamp;\n  }\n  /**\n   * Returns the type of the GC node. Currently, there are nodes that belong to the root (\"/\"), data stores or\n   * blob manager.\n   */\n\n\n  getNodeType(nodePath) {\n    var _a;\n\n    if (this.isBlobPath(nodePath)) {\n      return GCNodeType.Blob;\n    }\n\n    return (_a = this.dataStores.getGCNodeType(nodePath)) !== null && _a !== void 0 ? _a : GCNodeType.Other;\n  }\n  /**\n   * Called by GC to retrieve the package path of the node with the given path. The node should belong to a\n   * data store or an attachment blob.\n   */\n\n\n  getGCNodePackagePath(nodePath) {\n    var _this19 = this;\n\n    return _asyncToGenerator(function* () {\n      switch (_this19.getNodeType(nodePath)) {\n        case GCNodeType.Blob:\n          return [\"_blobs\"];\n\n        case GCNodeType.DataStore:\n        case GCNodeType.SubDataStore:\n          return _this19.dataStores.getDataStorePackagePath(nodePath);\n\n        default:\n          assert(false, 0x2de\n          /* \"Package path requested for unsupported node type.\" */\n          );\n      }\n    })();\n  }\n  /**\n   * Returns whether a given path is for attachment blobs that are in the format - \"/BlobManager.basePath/...\".\n   */\n\n\n  isBlobPath(path) {\n    const pathParts = path.split(\"/\");\n\n    if (pathParts.length < 2 || pathParts[1] !== BlobManager.basePath) {\n      return false;\n    }\n\n    return true;\n  }\n  /**\n   * Runs garbage collection and updates the reference / used state of the nodes in the container.\n   * @returns the statistics of the garbage collection run.\n   */\n\n\n  collectGarbage(options) {\n    var _this20 = this;\n\n    return _asyncToGenerator(function* () {\n      return _this20.garbageCollector.collectGarbage(options);\n    })();\n  }\n  /**\n   * Called when a new outbound reference is added to another node. This is used by garbage collection to identify\n   * all references added in the system.\n   * @param srcHandle - The handle of the node that added the reference.\n   * @param outboundHandle - The handle of the outbound node that is referenced.\n   */\n\n\n  addedGCOutboundReference(srcHandle, outboundHandle) {\n    this.garbageCollector.addedOutboundReference(srcHandle.absolutePath, outboundHandle.absolutePath);\n  }\n  /**\n   * Generates the summary tree, uploads it to storage, and then submits the summarize op.\n   * This is intended to be called by the summarizer, since it is the implementation of\n   * ISummarizerInternalsProvider.submitSummary.\n   * It takes care of state management at the container level, including pausing inbound\n   * op processing, updating SummarizerNode state tracking, and garbage collection.\n   * @param options - options controlling how the summary is generated or submitted\n   */\n\n\n  submitSummary(options) {\n    var _this21 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a, _b, _c;\n\n      const {\n        fullTree,\n        refreshLatestAck,\n        summaryLogger\n      } = options; // The summary number for this summary. This will be updated during the summary process, so get it now and\n      // use it for all events logged during this summary.\n\n      const summaryNumber = _this21.nextSummaryNumber;\n      const summaryNumberLogger = ChildLogger.create(summaryLogger, undefined, {\n        all: {\n          summaryNumber\n        }\n      });\n      let latestSnapshotVersionId;\n\n      if (refreshLatestAck) {\n        const latestSnapshotInfo = yield _this21.refreshLatestSummaryAckFromServer(ChildLogger.create(summaryNumberLogger, undefined, {\n          all: {\n            safeSummary: true\n          }\n        }));\n        const latestSnapshotRefSeq = latestSnapshotInfo.latestSnapshotRefSeq;\n        latestSnapshotVersionId = latestSnapshotInfo.latestSnapshotVersionId;\n\n        if (latestSnapshotRefSeq > _this21.deltaManager.lastSequenceNumber) {\n          // We need to catch up to the latest summary's reference sequence number before pausing.\n          yield PerformanceEvent.timedExecAsync(summaryNumberLogger, {\n            eventName: \"WaitingForSeq\",\n            lastSequenceNumber: _this21.deltaManager.lastSequenceNumber,\n            targetSequenceNumber: latestSnapshotRefSeq,\n            lastKnownSeqNumber: _this21.deltaManager.lastKnownSeqNumber\n          }, /*#__PURE__*/_asyncToGenerator(function* () {\n            return waitForSeq(_this21.deltaManager, latestSnapshotRefSeq);\n          }), {\n            start: true,\n            end: true,\n            cancel: \"error\"\n          });\n        }\n      }\n\n      try {\n        yield _this21.deltaManager.inbound.pause();\n        const summaryRefSeqNum = _this21.deltaManager.lastSequenceNumber;\n        const minimumSequenceNumber = _this21.deltaManager.minimumSequenceNumber;\n        const message = `Summary @${summaryRefSeqNum}:${_this21.deltaManager.minimumSequenceNumber}`; // We should be here is we haven't processed be here. If we are of if the last message's sequence number\n        // doesn't match the last processed sequence number, log an error.\n\n        if (summaryRefSeqNum !== ((_a = _this21.deltaManager.lastMessage) === null || _a === void 0 ? void 0 : _a.sequenceNumber)) {\n          summaryNumberLogger.sendErrorEvent({\n            eventName: \"LastSequenceMismatch\",\n            error: message\n          });\n        }\n\n        _this21.summarizerNode.startSummary(summaryRefSeqNum, summaryNumberLogger); // Helper function to check whether we should still continue between each async step.\n\n\n        const checkContinue = () => {\n          // Do not check for loss of connectivity directly! Instead leave it up to\n          // RunWhileConnectedCoordinator to control policy in a single place.\n          // This will allow easier change of design if we chose to. For example, we may chose to allow\n          // summarizer to reconnect in the future.\n          // Also checking for cancellation is a must as summary process may be abandoned for other reasons,\n          // like loss of connectivity for main (interactive) client.\n          if (options.cancellationToken.cancelled) {\n            return {\n              continue: false,\n              error: \"disconnected\"\n            };\n          } // That said, we rely on submitSystemMessage() that today only works in connected state.\n          // So if we fail here, it either means that RunWhileConnectedCoordinator does not work correctly,\n          // OR that design changed and we need to remove this check and fix submitSystemMessage.\n\n\n          assert(_this21.connected, 0x258\n          /* \"connected\" */\n          ); // Ensure that lastSequenceNumber has not changed after pausing.\n          // We need the summary op's reference sequence number to match our summary sequence number,\n          // otherwise we'll get the wrong sequence number stamped on the summary's .protocol attributes.\n\n          if (_this21.deltaManager.lastSequenceNumber !== summaryRefSeqNum) {\n            return {\n              continue: false,\n              // eslint-disable-next-line max-len\n              error: `lastSequenceNumber changed before uploading to storage. ${_this21.deltaManager.lastSequenceNumber} !== ${summaryRefSeqNum}`\n            };\n          }\n\n          return {\n            continue: true\n          };\n        };\n\n        let continueResult = checkContinue();\n\n        if (!continueResult.continue) {\n          return {\n            stage: \"base\",\n            referenceSequenceNumber: summaryRefSeqNum,\n            minimumSequenceNumber,\n            error: continueResult.error\n          };\n        }\n\n        const trace = Trace.start();\n        let summarizeResult; // If the GC state needs to be reset, we need to force a full tree summary and update the unreferenced\n        // state of all the nodes.\n\n        const forcedFullTree = _this21.garbageCollector.summaryStateNeedsReset;\n\n        try {\n          summarizeResult = yield _this21.summarize({\n            fullTree: fullTree || forcedFullTree,\n            trackState: true,\n            summaryLogger: summaryNumberLogger,\n            runGC: _this21.garbageCollector.shouldRunGC\n          });\n        } catch (error) {\n          return {\n            stage: \"base\",\n            referenceSequenceNumber: summaryRefSeqNum,\n            minimumSequenceNumber,\n            error\n          };\n        }\n\n        const {\n          summary: summaryTree,\n          stats: partialStats\n        } = summarizeResult; // Now that we have generated the summary, update the message at last summary to the last message processed.\n\n        _this21.messageAtLastSummary = _this21.deltaManager.lastMessage; // Counting dataStores and handles\n        // Because handles are unchanged dataStores in the current logic,\n        // summarized dataStore count is total dataStore count minus handle count\n\n        const dataStoreTree = _this21.disableIsolatedChannels ? summaryTree : summaryTree.tree[channelsTreeName];\n        assert(dataStoreTree.type === SummaryType.Tree, 0x1fc\n        /* \"summary is not a tree\" */\n        );\n        const handleCount = Object.values(dataStoreTree.tree).filter(value => value.type === SummaryType.Handle).length;\n        const gcSummaryTreeStats = summaryTree.tree[gcTreeKey] ? calculateStats(summaryTree.tree[gcTreeKey]) : undefined;\n        const summaryStats = Object.assign({\n          dataStoreCount: _this21.dataStores.size,\n          summarizedDataStoreCount: _this21.dataStores.size - handleCount,\n          gcStateUpdatedDataStoreCount: (_b = summarizeResult.gcStats) === null || _b === void 0 ? void 0 : _b.updatedDataStoreCount,\n          gcBlobNodeCount: gcSummaryTreeStats === null || gcSummaryTreeStats === void 0 ? void 0 : gcSummaryTreeStats.blobNodeCount,\n          gcTotalBlobsSize: gcSummaryTreeStats === null || gcSummaryTreeStats === void 0 ? void 0 : gcSummaryTreeStats.totalBlobSize,\n          opsSizesSinceLastSummary: _this21.opTracker.opsSizeAccumulator,\n          nonSystemOpsSinceLastSummary: _this21.opTracker.nonSystemOpCount,\n          summaryNumber\n        }, partialStats);\n        const generateSummaryData = {\n          referenceSequenceNumber: summaryRefSeqNum,\n          minimumSequenceNumber,\n          summaryTree,\n          summaryStats,\n          generateDuration: trace.trace().duration,\n          forcedFullTree\n        };\n        continueResult = checkContinue();\n\n        if (!continueResult.continue) {\n          return Object.assign(Object.assign({\n            stage: \"generate\"\n          }, generateSummaryData), {\n            error: continueResult.error\n          });\n        } // It may happen that the lastAck it not correct due to missing summaryAck in case of single commit\n        // summary. So if the previous summarizer closes just after submitting the summary and before\n        // submitting the summaryOp then we can't rely on summaryAck. So in case we have\n        // latestSnapshotVersionId from storage and it does not match with the lastAck ackHandle, then use\n        // the one fetched from storage as parent as that is the latest.\n\n\n        const lastAck = _this21.summaryCollection.latestAck;\n        let summaryContext;\n\n        if ((lastAck === null || lastAck === void 0 ? void 0 : lastAck.summaryAck.contents.handle) !== latestSnapshotVersionId && latestSnapshotVersionId !== undefined) {\n          summaryContext = {\n            proposalHandle: undefined,\n            ackHandle: latestSnapshotVersionId,\n            referenceSequenceNumber: summaryRefSeqNum\n          };\n        } else if (lastAck === undefined) {\n          summaryContext = {\n            proposalHandle: undefined,\n            ackHandle: (_c = _this21.context.getLoadedFromVersion()) === null || _c === void 0 ? void 0 : _c.id,\n            referenceSequenceNumber: summaryRefSeqNum\n          };\n        } else {\n          summaryContext = {\n            proposalHandle: lastAck.summaryOp.contents.handle,\n            ackHandle: lastAck.summaryAck.contents.handle,\n            referenceSequenceNumber: summaryRefSeqNum\n          };\n        }\n\n        let handle;\n\n        try {\n          handle = yield _this21.storage.uploadSummaryWithContext(summarizeResult.summary, summaryContext);\n        } catch (error) {\n          return Object.assign(Object.assign({\n            stage: \"generate\"\n          }, generateSummaryData), {\n            error\n          });\n        }\n\n        const parent = summaryContext.ackHandle;\n        const summaryMessage = {\n          handle,\n          // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n          head: parent,\n          message,\n          parents: parent ? [parent] : []\n        };\n        const uploadData = Object.assign(Object.assign({}, generateSummaryData), {\n          handle,\n          uploadDuration: trace.trace().duration\n        });\n        continueResult = checkContinue();\n\n        if (!continueResult.continue) {\n          return Object.assign(Object.assign({\n            stage: \"upload\"\n          }, uploadData), {\n            error: continueResult.error\n          });\n        }\n\n        let clientSequenceNumber;\n\n        try {\n          clientSequenceNumber = _this21.submitSystemMessage(MessageType.Summarize, summaryMessage);\n        } catch (error) {\n          return Object.assign(Object.assign({\n            stage: \"upload\"\n          }, uploadData), {\n            error\n          });\n        }\n\n        const submitData = Object.assign(Object.assign({\n          stage: \"submit\"\n        }, uploadData), {\n          clientSequenceNumber,\n          submitOpDuration: trace.trace().duration\n        });\n\n        _this21.summarizerNode.completeSummary(handle);\n\n        _this21.opTracker.reset();\n\n        return submitData;\n      } finally {\n        // Cleanup wip summary in case of failure\n        _this21.summarizerNode.clearSummary(); // Restart the delta manager\n\n\n        _this21.deltaManager.inbound.resume();\n      }\n    })();\n  }\n\n  processRemoteChunkedMessage(message) {\n    if (message.type !== ContainerMessageType.ChunkedOp) {\n      return message;\n    }\n\n    const clientId = message.clientId;\n    const chunkedContent = message.contents;\n    this.addChunk(clientId, chunkedContent);\n\n    if (chunkedContent.chunkId === chunkedContent.totalChunks) {\n      const newMessage = Object.assign({}, message); // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n\n      const serializedContent = this.chunkMap.get(clientId).join(\"\");\n      newMessage.contents = JSON.parse(serializedContent);\n      newMessage.type = chunkedContent.originalType;\n      this.clearPartialChunks(clientId);\n      return newMessage;\n    }\n\n    return message;\n  }\n\n  addChunk(clientId, chunkedContent) {\n    let map = this.chunkMap.get(clientId);\n\n    if (map === undefined) {\n      map = [];\n      this.chunkMap.set(clientId, map);\n    }\n\n    assert(chunkedContent.chunkId === map.length + 1, 0x131\n    /* \"Mismatch between new chunkId and expected chunkMap\" */\n    ); // 1-based indexing\n\n    map.push(chunkedContent.contents);\n  }\n\n  clearPartialChunks(clientId) {\n    if (this.chunkMap.has(clientId)) {\n      this.chunkMap.delete(clientId);\n    }\n  }\n\n  updateDocumentDirtyState(dirty) {\n    if (this.dirtyContainer === dirty) {\n      return;\n    }\n\n    this.dirtyContainer = dirty;\n\n    if (this.emitDirtyDocumentEvent) {\n      this.emit(dirty ? \"dirty\" : \"saved\");\n      this.context.updateDirtyContainerState(dirty);\n    }\n  }\n\n  submitDataStoreOp(id, contents, localOpMetadata = undefined) {\n    const envelope = {\n      address: id,\n      contents\n    };\n    this.submit(ContainerMessageType.FluidDataStoreOp, envelope, localOpMetadata);\n  }\n\n  submitDataStoreAliasOp(contents, localOpMetadata) {\n    const aliasMessage = contents;\n\n    if (!isDataStoreAliasMessage(aliasMessage)) {\n      throw new UsageError(\"malformedDataStoreAliasMessage\");\n    }\n\n    this.submit(ContainerMessageType.Alias, contents, localOpMetadata);\n  }\n\n  uploadBlob(blob) {\n    var _this22 = this;\n\n    return _asyncToGenerator(function* () {\n      _this22.verifyNotClosed();\n\n      return _this22.blobManager.createBlob(blob);\n    })();\n  }\n\n  submit(type, content, localOpMetadata = undefined, opMetadata = undefined) {\n    this.verifyNotClosed(); // There should be no ops in detached container state!\n\n    assert(this.attachState !== AttachState.Detached, 0x132\n    /* \"sending ops in detached container\" */\n    );\n    let clientSequenceNumber = -1;\n    let opMetadataInternal = opMetadata;\n\n    if (this.canSendOps()) {\n      const serializedContent = JSON.stringify(content);\n      const maxOpSize = this.context.deltaManager.maxMessageSize; // If in TurnBased flush mode we will trigger a flush at the next turn break\n\n      if (this.flushMode === FlushMode.TurnBased && !this.needsFlush) {\n        opMetadataInternal = Object.assign(Object.assign({}, opMetadata), {\n          batch: true\n        });\n        this.needsFlush = true; // Use Promise.resolve().then() to queue a microtask to detect the end of the turn and force a flush.\n\n        if (!this.flushTrigger) {\n          // eslint-disable-next-line @typescript-eslint/no-floating-promises\n          Promise.resolve().then(() => {\n            this.flushTrigger = false;\n            this.flush();\n          });\n        }\n      }\n\n      clientSequenceNumber = this.submitMaybeChunkedMessages(type, content, serializedContent, maxOpSize, this._flushMode === FlushMode.TurnBased, opMetadataInternal);\n    } // Let the PendingStateManager know that a message was submitted.\n\n\n    this.pendingStateManager.onSubmitMessage(type, clientSequenceNumber, this.deltaManager.lastSequenceNumber, content, localOpMetadata, opMetadataInternal);\n\n    if (this.isContainerMessageDirtyable(type, content)) {\n      this.updateDocumentDirtyState(true);\n    }\n  }\n\n  submitMaybeChunkedMessages(type, content, serializedContent, serverMaxOpSize, batch, opMetadataInternal = undefined) {\n    if (this._maxOpSizeInBytes >= 0) {\n      // Chunking disabled\n      if (!serializedContent || serializedContent.length <= this._maxOpSizeInBytes) {\n        return this.submitRuntimeMessage(type, content, batch, opMetadataInternal);\n      } // When chunking is disabled, we ignore the server max message size\n      // and if the content length is larger than the client configured message size\n      // instead of splitting the content, we will fail by explicitly close the container\n\n\n      this.closeFn(new GenericError(\"OpTooLarge\",\n      /* error */\n      undefined, {\n        length: {\n          value: serializedContent.length,\n          tag: TelemetryDataTag.PackageData\n        },\n        limit: {\n          value: this._maxOpSizeInBytes,\n          tag: TelemetryDataTag.PackageData\n        }\n      }));\n      return -1;\n    } // Chunking enabled, fallback on the server's max message size\n    // and split the content accordingly\n\n\n    if (!serializedContent || serializedContent.length <= serverMaxOpSize) {\n      return this.submitRuntimeMessage(type, content, batch, opMetadataInternal);\n    }\n\n    return this.submitChunkedMessage(type, serializedContent, serverMaxOpSize);\n  }\n\n  submitChunkedMessage(type, content, maxOpSize) {\n    const contentLength = content.length;\n    const chunkN = Math.floor((contentLength - 1) / maxOpSize) + 1;\n    let offset = 0;\n    let clientSequenceNumber = 0;\n\n    for (let i = 1; i <= chunkN; i = i + 1) {\n      const chunkedOp = {\n        chunkId: i,\n        contents: content.substr(offset, maxOpSize),\n        originalType: type,\n        totalChunks: chunkN\n      };\n      offset += maxOpSize;\n      clientSequenceNumber = this.submitRuntimeMessage(ContainerMessageType.ChunkedOp, chunkedOp, false);\n    }\n\n    return clientSequenceNumber;\n  }\n\n  submitSystemMessage(type, contents) {\n    this.verifyNotClosed();\n    assert(this.connected, 0x133\n    /* \"Container disconnected when trying to submit system message\" */\n    ); // System message should not be sent in the middle of the batch.\n    // That said, we can preserve existing behavior by not flushing existing buffer.\n    // That might be not what caller hopes to get, but we can look deeper if telemetry tells us it's a problem.\n\n    const middleOfBatch = this.flushMode === FlushMode.TurnBased && this.needsFlush;\n\n    if (middleOfBatch) {\n      this.mc.logger.sendErrorEvent({\n        eventName: \"submitSystemMessageError\",\n        type\n      });\n    }\n\n    return this.context.submitFn(type, contents, middleOfBatch);\n  }\n\n  submitRuntimeMessage(type, contents, batch, appData) {\n    this.verifyNotClosed();\n    assert(this.connected, 0x259\n    /* \"Container disconnected when trying to submit system message\" */\n    );\n    const payload = {\n      type,\n      contents\n    };\n    return this.context.submitFn(MessageType.Operation, payload, batch, appData);\n  }\n  /**\n   * Throw an error if the runtime is closed.  Methods that are expected to potentially\n   * be called after dispose due to asynchrony should not call this.\n   */\n\n\n  verifyNotClosed() {\n    if (this._disposed) {\n      throw new Error(\"Runtime is closed\");\n    }\n  }\n  /**\n   * Finds the right store and asks it to resubmit the message. This typically happens when we\n   * reconnect and there are pending messages.\n   * @param content - The content of the original message.\n   * @param localOpMetadata - The local metadata associated with the original message.\n   */\n\n\n  reSubmit(type, content, localOpMetadata, opMetadata) {\n    switch (type) {\n      case ContainerMessageType.FluidDataStoreOp:\n        // For Operations, call resubmitDataStoreOp which will find the right store\n        // and trigger resubmission on it.\n        this.dataStores.resubmitDataStoreOp(content, localOpMetadata);\n        break;\n\n      case ContainerMessageType.Attach:\n      case ContainerMessageType.Alias:\n        this.submit(type, content, localOpMetadata);\n        break;\n\n      case ContainerMessageType.ChunkedOp:\n        throw new Error(`chunkedOp not expected here`);\n\n      case ContainerMessageType.BlobAttach:\n        this.submit(type, content, localOpMetadata, opMetadata);\n        break;\n\n      case ContainerMessageType.Rejoin:\n        this.submit(type, content);\n        break;\n\n      default:\n        unreachableCase(type, `Unknown ContainerMessageType: ${type}`);\n    }\n  }\n\n  rollback(type, content, localOpMetadata) {\n    switch (type) {\n      case ContainerMessageType.FluidDataStoreOp:\n        // For operations, call rollbackDataStoreOp which will find the right store\n        // and trigger rollback on it.\n        this.dataStores.rollbackDataStoreOp(content, localOpMetadata);\n        break;\n\n      default:\n        throw new Error(`Can't rollback ${type}`);\n    }\n  }\n  /** Implementation of ISummarizerInternalsProvider.refreshLatestSummaryAck */\n\n\n  refreshLatestSummaryAck(proposalHandle, ackHandle, summaryRefSeq, summaryLogger) {\n    var _this23 = this;\n\n    return _asyncToGenerator(function* () {\n      const readAndParseBlob = /*#__PURE__*/function () {\n        var _ref9 = _asyncToGenerator(function* (id) {\n          return readAndParse(_this23.storage, id);\n        });\n\n        return function readAndParseBlob(_x9) {\n          return _ref9.apply(this, arguments);\n        };\n      }();\n\n      const {\n        snapshotTree\n      } = yield _this23.fetchSnapshotFromStorage(ackHandle, summaryLogger, {\n        eventName: \"RefreshLatestSummaryGetSnapshot\",\n        ackHandle,\n        summaryRefSeq,\n        fetchLatest: false\n      });\n      const result = yield _this23.summarizerNode.refreshLatestSummary(proposalHandle, summaryRefSeq, /*#__PURE__*/_asyncToGenerator(function* () {\n        return snapshotTree;\n      }), readAndParseBlob, summaryLogger); // Notify the garbage collector so it can update its latest summary state.\n\n      yield _this23.garbageCollector.latestSummaryStateRefreshed(result, readAndParseBlob);\n    })();\n  }\n  /**\n   * Fetches the latest snapshot from storage and uses it to refresh SummarizerNode's\n   * internal state as it should be considered the latest summary ack.\n   * @param summaryLogger - logger to use when fetching snapshot from storage\n   * @returns downloaded snapshot's reference sequence number\n   */\n\n\n  refreshLatestSummaryAckFromServer(summaryLogger) {\n    var _this24 = this;\n\n    return _asyncToGenerator(function* () {\n      const {\n        snapshotTree,\n        versionId\n      } = yield _this24.fetchSnapshotFromStorage(null, summaryLogger, {\n        eventName: \"RefreshLatestSummaryGetSnapshot\",\n        fetchLatest: true\n      });\n\n      const readAndParseBlob = /*#__PURE__*/function () {\n        var _ref11 = _asyncToGenerator(function* (id) {\n          return readAndParse(_this24.storage, id);\n        });\n\n        return function readAndParseBlob(_x10) {\n          return _ref11.apply(this, arguments);\n        };\n      }();\n\n      const latestSnapshotRefSeq = yield seqFromTree(snapshotTree, readAndParseBlob);\n      const result = yield _this24.summarizerNode.refreshLatestSummary(undefined, latestSnapshotRefSeq, /*#__PURE__*/_asyncToGenerator(function* () {\n        return snapshotTree;\n      }), readAndParseBlob, summaryLogger); // Notify the garbage collector so it can update its latest summary state.\n\n      yield _this24.garbageCollector.latestSummaryStateRefreshed(result, readAndParseBlob);\n      return {\n        latestSnapshotRefSeq,\n        latestSnapshotVersionId: versionId\n      };\n    })();\n  }\n\n  fetchSnapshotFromStorage(versionId, logger, event) {\n    var _this25 = this;\n\n    return _asyncToGenerator(function* () {\n      return PerformanceEvent.timedExecAsync(logger, event, /*#__PURE__*/function () {\n        var _ref13 = _asyncToGenerator(function* (perfEvent) {\n          const stats = {};\n          const trace = Trace.start();\n          const versions = yield _this25.storage.getVersions(versionId, 1);\n          assert(!!versions && !!versions[0], 0x137\n          /* \"Failed to get version from storage\" */\n          );\n          stats.getVersionDuration = trace.trace().duration;\n          const maybeSnapshot = yield _this25.storage.getSnapshotTree(versions[0]);\n          assert(!!maybeSnapshot, 0x138\n          /* \"Failed to get snapshot from storage\" */\n          );\n          stats.getSnapshotDuration = trace.trace().duration;\n          perfEvent.end(stats);\n          return {\n            snapshotTree: maybeSnapshot,\n            versionId: versions[0].id\n          };\n        });\n\n        return function (_x11) {\n          return _ref13.apply(this, arguments);\n        };\n      }());\n    })();\n  }\n\n  notifyAttaching(snapshot) {\n    var _a;\n\n    if ((_a = this.mc.config.getBoolean(\"enableOfflineLoad\")) !== null && _a !== void 0 ? _a : this.runtimeOptions.enableOfflineLoad) {\n      this.baseSnapshotBlobs = SerializedSnapshotStorage.serializeTreeWithBlobContents(snapshot);\n    }\n  }\n\n  getSnapshotBlobs() {\n    var _this26 = this;\n\n    return _asyncToGenerator(function* () {\n      var _a;\n\n      if (!((_a = _this26.mc.config.getBoolean(\"enableOfflineLoad\")) !== null && _a !== void 0 ? _a : _this26.runtimeOptions.enableOfflineLoad) || _this26.attachState !== AttachState.Attached || _this26.context.pendingLocalState) {\n        return;\n      }\n\n      assert(!!_this26.context.baseSnapshot, 0x2e5\n      /* \"Must have a base snapshot\" */\n      );\n      _this26.baseSnapshotBlobs = yield SerializedSnapshotStorage.serializeTree(_this26.context.baseSnapshot, _this26.storage);\n    })();\n  }\n\n  getPendingLocalState() {\n    var _a;\n\n    if (!((_a = this.mc.config.getBoolean(\"enableOfflineLoad\")) !== null && _a !== void 0 ? _a : this.runtimeOptions.enableOfflineLoad)) {\n      throw new UsageError(\"can't get state when offline load disabled\");\n    }\n\n    const previousPendingState = this.context.pendingLocalState;\n\n    if (previousPendingState) {\n      return {\n        pending: this.pendingStateManager.getLocalState(),\n        snapshotBlobs: previousPendingState.snapshotBlobs,\n        baseSnapshot: previousPendingState.baseSnapshot,\n        savedOps: this.savedOps\n      };\n    }\n\n    assert(!!this.context.baseSnapshot, 0x2e6\n    /* \"Must have a base snapshot\" */\n    );\n    assert(!!this.baseSnapshotBlobs, 0x2e7\n    /* \"Must serialize base snapshot blobs before getting runtime state\" */\n    );\n    return {\n      pending: this.pendingStateManager.getLocalState(),\n      snapshotBlobs: this.baseSnapshotBlobs,\n      baseSnapshot: this.context.baseSnapshot,\n      savedOps: this.savedOps\n    };\n  }\n  /**\n   * * Forms a function that will request a Summarizer.\n   * @param loaderRouter - the loader acting as an IFluidRouter\n   * */\n\n\n  formRequestSummarizerFn(loaderRouter) {\n    return /*#__PURE__*/_asyncToGenerator(function* () {\n      const request = {\n        headers: {\n          [LoaderHeader.cache]: false,\n          [LoaderHeader.clientDetails]: {\n            capabilities: {\n              interactive: false\n            },\n            type: summarizerClientType\n          },\n          [DriverHeader.summarizingClient]: true,\n          [LoaderHeader.reconnect]: false\n        },\n        url: \"/_summarizer\"\n      };\n      const fluidObject = yield requestFluidObject(loaderRouter, request);\n      const summarizer = fluidObject.ISummarizer;\n\n      if (!summarizer) {\n        throw new UsageError(\"Fluid object does not implement ISummarizer\");\n      }\n\n      return summarizer;\n    });\n  }\n\n  processSavedOps(state) {\n    var _this27 = this;\n\n    return _asyncToGenerator(function* () {\n      for (const op of state.savedOps) {\n        _this27.process(op, false);\n\n        yield _this27.pendingStateManager.applyStashedOpsAt(op.sequenceNumber);\n      } // we may not have seen every sequence number (because of system ops) so apply everything once we\n      // don't have any more saved ops\n\n\n      yield _this27.pendingStateManager.applyStashedOpsAt();\n    })();\n  }\n\n}\n/**\n * Wait for a specific sequence number. Promise should resolve when we reach that number,\n * or reject if closed.\n */\n\nconst waitForSeq = /*#__PURE__*/function () {\n  var _ref15 = _asyncToGenerator(function* (deltaManager, targetSeq) {\n    return new Promise((resolve, reject) => {\n      // TODO: remove cast to any when actual event is determined\n      deltaManager.on(\"closed\", reject);\n\n      const handleOp = message => {\n        if (message.sequenceNumber >= targetSeq) {\n          resolve();\n          deltaManager.off(\"op\", handleOp);\n        }\n      };\n\n      deltaManager.on(\"op\", handleOp);\n    });\n  });\n\n  return function waitForSeq(_x12, _x13) {\n    return _ref15.apply(this, arguments);\n  };\n}(); //# sourceMappingURL=containerRuntime.js.map","map":null,"metadata":{},"sourceType":"module"}